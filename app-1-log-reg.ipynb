{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master Thesis: Bankruptcy Prediction for European Countries\n",
    "Code written by Marc Zeugin (UZH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report, PrecisionRecallDisplay, confusion_matrix, RocCurveDisplay\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearnex.ensemble import RandomForestClassifier\n",
    "from sklearnex.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import IterativeImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.combine import SMOTEENN\n",
    "from skopt.space import Real, Integer\n",
    "from matplotlib import pyplot as plt\n",
    "from skopt import BayesSearchCV\n",
    "from joblib import dump, Memory\n",
    "from sklearnex.svm import SVC\n",
    "from itertools import product\n",
    "from tempfile import mkdtemp\n",
    "from shutil import rmtree\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "import pyarrow\n",
    "import glob\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup key variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine training/testing ratio, default is 0.2\n",
    "tt_size = 0.2\n",
    "# number of splits for k-fold crossvalidation, default is 5\n",
    "k_splits = 5\n",
    "# set number of jobs to run in parallel, -1 means all processors, default is 1\n",
    "jobs = -1\n",
    "# number of iterations for BayesSearchCV\n",
    "n_iterations = 40\n",
    "# select scoring model to optimize, default is average_precision, the value used for the precision-recall curve\n",
    "scoring_metric = 'average_precision'\n",
    "# label for classification report\n",
    "label = ['Non-Bankrupt', 'Bankrupt']\n",
    "\n",
    "# absolute path to dataset\n",
    "path = 'C:/Users/marczeugin/Documents/Masterthesis/datasets/'\n",
    "# extension of dataset type\n",
    "ext = '*.csv'\n",
    "\n",
    "# determine the size (in inches) of the precision-recall curve figure, default is (4, 2)\n",
    "figure_size = (4, 2)\n",
    "# set dpi of small graphs, default is 100\n",
    "dpi_low = 100\n",
    "# set dpi of medium graphs, default is 200\n",
    "dpi_med = 200\n",
    "# set dpi of large graphs, default is 250\n",
    "dpi_high = 250\n",
    "\n",
    "# enable subsample of total dataset to be used for hyperparameter tuning, default is True\n",
    "allow_subsample = True\n",
    "# set subsample size of total dataset, default is .1 e.g. 10%\n",
    "subsample_size = 0.1\n",
    "# enable quick overview to run with subsample\n",
    "allow_subsample_overview = True\n",
    "# enable hyperparameter tuning with subsample\n",
    "allow_subsample_hyperparameter = True\n",
    "\n",
    "# allow to load dataset with SMOTEENN already run and imputation already imputed, default is True\n",
    "allow_computed_set = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create model lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list = ['complete', 'without years', 'without macro', 'without years and macro', 'complete SMOTEENN', 'without years SMOTEENN', 'without macro SMOTEENN', 'without years and macro SMOTEENN']\n",
    "\n",
    "X_list = np.load('X_list.npy', allow_pickle=True).tolist()\n",
    "X_list_m = np.load('X_list_m.npy', allow_pickle=True).tolist()\n",
    "y_list = np.load('y_list.npy', allow_pickle=True).tolist()\n",
    "y_list_m = np.load('y_list_m.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. Hyperparameter tuning for Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.1. Without SMOTEENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_list_lr = dict()\n",
    "params_list_lr['solver'] = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "params_list_lr['penalty'] = ['none', 'l1', 'l2', 'elasticnet']\n",
    "params_list_lr['fit_intercept'] = [True, False]\n",
    "params_list_lr['C'] = Real(1e-6, 1000.0, prior='log-uniform')\n",
    "model = LogisticRegression(random_state=1, n_jobs=jobs, class_weight='balanced')\n",
    "kfold = StratifiedKFold(n_splits=k_splits, random_state=1, shuffle=True)\n",
    "search = BayesSearchCV(estimator=model, search_spaces=params_list_lr, scoring=scoring_metric, cv=kfold, error_score=0, random_state=1, n_jobs=jobs, n_iter=n_iterations)\n",
    "fig_cols = 2\n",
    "fig_rows = 4\n",
    "\n",
    "log_reg_means_list = []\n",
    "lr_names_list = []\n",
    "log_reg_params_list = []\n",
    "log_reg_max_means_list = []\n",
    "log_reg_best_result_list = []\n",
    "log_reg_best_C = []\n",
    "log_reg_best_penalty = []\n",
    "log_reg_best_solver = []\n",
    "log_reg_best_intercept = []\n",
    "\n",
    "for i in range(0, int(len(X_list_m))):\n",
    "    start = time.perf_counter()\n",
    "    grid_result = search.fit(X_list_m[i][0], y_list_m[i][0])\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "\n",
    "    lr_names = []\n",
    "    for k in range(len(params)):\n",
    "        new_string = params[k]['solver'] + ' ' + params[k]['penalty'] + ' ' + str(round(params[k]['C'],6)) + ' ' + str(params[k]['fit_intercept'])\n",
    "        lr_names.append(new_string)\n",
    "    \n",
    "    index_to_rm = []\n",
    "    for index, item in enumerate(means):\n",
    "        if item == 0.0:\n",
    "            index_to_rm.append(index)\n",
    "    means = np.delete(means, index_to_rm)\n",
    "    lr_names = np.delete(lr_names, index_to_rm)\n",
    "    params = np.delete(params, index_to_rm)\n",
    "    \n",
    "    index_to_rm2 = []\n",
    "    for index, item in enumerate(params):\n",
    "        if item in params[:index]:\n",
    "            index_to_rm2.append(index)\n",
    "    means = np.delete(means, index_to_rm2)\n",
    "    lr_names = np.delete(lr_names, index_to_rm2)\n",
    "    params = np.delete(params, index_to_rm2)\n",
    "    max_mean = np.argmax(means)\n",
    "    \n",
    "    log_reg_means_list.append(means)\n",
    "    lr_names_list.append(lr_names)\n",
    "    log_reg_params_list.append(params)\n",
    "    log_reg_max_means_list.append(max_mean)\n",
    "    log_reg_best_result_list.append(grid_result.best_score_)\n",
    "\n",
    "    print(f'Best {scoring_metric} of {round(means[max_mean],4)} for hyperparameters={params[max_mean]}')\n",
    "\n",
    "    end = time.perf_counter()\n",
    "    print(f'Ran hyperparameter tuning in {end-start:0.4f} seconds')\n",
    "\n",
    "    log_reg_best_C.append(params[max_mean]['C'])\n",
    "    log_reg_best_penalty.append(params[max_mean]['penalty'])\n",
    "    log_reg_best_solver.append(params[max_mean]['solver'])\n",
    "    log_reg_best_intercept.append(params[max_mean]['fit_intercept'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.2. With SMOTEENN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save pipeline in memory for faster processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cachedir = mkdtemp()\n",
    "memory = Memory(cachedir=cachedir, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_list_lr_smoteenn = dict()\n",
    "params_list_lr_smoteenn['model__solver'] = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "params_list_lr_smoteenn['model__penalty'] = ['none', 'l1', 'l2', 'elasticnet']\n",
    "params_list_lr_smoteenn['model__fit_intercept'] = [True, False]\n",
    "params_list_lr_smoteenn['model__C'] = Real(1e-6, 1000.0, prior='log-uniform')\n",
    "pipe = Pipeline([('SMOTEENN', SMOTEENN(smote=SMOTE(sampling_strategy='minority', random_state=1), enn=EditedNearestNeighbours(sampling_strategy='all'), \n",
    "                                       random_state=1, n_jobs=jobs)), ('model', LogisticRegression(random_state=1, n_jobs=jobs))], memory=memory)\n",
    "kfold = StratifiedKFold(n_splits=3, random_state=1, shuffle=True)\n",
    "search = BayesSearchCV(estimator=pipe, search_spaces=params_list_lr_smoteenn, scoring=scoring_metric, cv=kfold, error_score=0, random_state=1, n_jobs=jobs, n_iter=n_iterations)\n",
    "\n",
    "for i in range(0, int(len(X_list_m))):\n",
    "    start = time.perf_counter()\n",
    "    grid_result = search.fit(X_list_m[i][0], y_list_m[i][0])\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "\n",
    "    lr_names = []\n",
    "    for k in range(len(params)):\n",
    "        new_string = params[k]['model__solver'] + ' ' + params[k]['model__penalty'] + ' ' + str(round(params[k]['model__C'],6)) + ' ' + str(params[k]['model__fit_intercept'])\n",
    "        lr_names.append(new_string)\n",
    "    \n",
    "    index_to_rm = []\n",
    "    for index, item in enumerate(means):\n",
    "        if item == 0.0:\n",
    "            index_to_rm.append(index)\n",
    "    means = np.delete(means, index_to_rm)\n",
    "    lr_names = np.delete(lr_names, index_to_rm)\n",
    "    params = np.delete(params, index_to_rm)\n",
    "    \n",
    "    index_to_rm2 = []\n",
    "    for index, item in enumerate(params):\n",
    "        if item in params[:index]:\n",
    "            index_to_rm2.append(index)\n",
    "    means = np.delete(means, index_to_rm2)\n",
    "    lr_names = np.delete(lr_names, index_to_rm2)\n",
    "    params = np.delete(params, index_to_rm2)\n",
    "    max_mean = np.argmax(means)\n",
    "    \n",
    "    log_reg_means_list.append(means)\n",
    "    lr_names_list.append(lr_names)\n",
    "    log_reg_params_list.append(params)\n",
    "    log_reg_max_means_list.append(max_mean)\n",
    "    log_reg_best_result_list.append(grid_result.best_score_)\n",
    "\n",
    "    print(f'Best {scoring_metric} of {round(means[max_mean],4)} for hyperparameters={params[max_mean]}')\n",
    "\n",
    "    end = time.perf_counter()\n",
    "    print(f'Ran hyperparameter tuning in {end-start:0.4f} seconds')\n",
    "\n",
    "    log_reg_best_C.append(params[max_mean]['model__C'])\n",
    "    log_reg_best_penalty.append(params[max_mean]['model__penalty'])\n",
    "    log_reg_best_solver.append(params[max_mean]['model__solver'])\n",
    "    log_reg_best_intercept.append(params[max_mean]['model__fit_intercept'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = -1\n",
    "row = 0\n",
    "\n",
    "fig, ax = plt.subplots(int(len(log_reg_means_list)/2), 2)\n",
    "fig.set_size_inches((30, 30))\n",
    "fig.tight_layout(h_pad=17.0, w_pad=4)\n",
    "fig.set_dpi(dpi_low)\n",
    "for i in range(0, int(len(log_reg_means_list))):\n",
    "    if i % 2 == 0:\n",
    "        col += 1\n",
    "        row = 0\n",
    "    if i % 2 == 1:\n",
    "        row += 1\n",
    "        \n",
    "    ax[col, row].plot(range(len(log_reg_means_list[i])), log_reg_means_list[i], color='grey', marker='o', markerfacecolor='black')\n",
    "    ax[col, row].plot(log_reg_max_means_list[i], log_reg_best_result_list[i], marker='o', markerfacecolor='red', markeredgecolor=\"red\")\n",
    "    ax[col, row].set_title(f'Mean {scoring_metric} for linear regression with stratified {k_splits}-fold crossvalidation\\n{name_list[i]}')\n",
    "    ax[col, row].set_xticks(range(len(log_reg_means_list[i])))\n",
    "    ax[col, row].set_xticklabels(lr_names_list[i], rotation=45, ha='right')\n",
    "    ax[col, row].set_xlabel('Linear Regression Hyperparameters (solver, penalty, C, intercept)')\n",
    "    ax[col, row].set_ylabel(scoring_metric)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. Logistic regression with optimal hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_models = []\n",
    "log_reg_accuracy = []\n",
    "log_reg_precision = []\n",
    "log_reg_recall = []\n",
    "log_reg_f1 = []\n",
    "log_reg_classification_report = []\n",
    "log_reg_test_prediction = []\n",
    "\n",
    "for i, variant in enumerate(X_list):\n",
    "    start = time.perf_counter()\n",
    "    log_reg = LogisticRegression(penalty=log_reg_best_penalty[i], solver=log_reg_best_solver[i], C=log_reg_best_C[i], fit_intercept=log_reg_best_intercept[i], n_jobs=jobs, random_state=1, class_weight='balanced')\n",
    "    log_reg.fit(variant[0], y_list[i][0])\n",
    "    log_reg_test_pred = log_reg.predict(variant[1])\n",
    "    log_reg_test_prediction.append(log_reg_test_pred)\n",
    "\n",
    "    log_reg_accuracy.append(log_reg.score(variant[1], y_list[i][1]))\n",
    "    log_reg_precision.append(precision_score(y_list[i][1], log_reg_test_pred))\n",
    "    log_reg_recall.append(recall_score(y_list[i][1], log_reg_test_pred))\n",
    "    log_reg_f1.append(f1_score(y_list[i][1], log_reg_test_pred))\n",
    "\n",
    "    log_reg_classification_report.append(classification_report(y_list[i][1], log_reg_test_pred, target_names=label))\n",
    "\n",
    "    end = time.perf_counter()\n",
    "    print(f'Ran model training and testing in {end-start:0.4f} seconds')\n",
    "    \n",
    "    log_reg_models.append(log_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_pr = []\n",
    "\n",
    "fig, ax = plt.subplots(4, 2)\n",
    "fig.set_size_inches((20, 15))\n",
    "fig.tight_layout(pad=5.0)\n",
    "col = -1\n",
    "row = 0\n",
    "for i in range(0, int(len(log_reg_means_list))):\n",
    "    if i % 2 == 0:\n",
    "        col += 1\n",
    "        row = 0\n",
    "    elif i % 2 == 1:\n",
    "        row += 1\n",
    "    \n",
    "    log_reg_display = PrecisionRecallDisplay.from_estimator(log_reg_models[i], X_list[i][1], y_list[i][1], name='Logistic Regression', color='black', ax=ax[col, row])\n",
    "    log_reg_pr.append(log_reg_display)\n",
    "    ax[col, row].set_title('Logistic Regression Precision-Recall curve '+name_list[i], fontweight='bold')\n",
    "    ax[col, row].legend(loc='best')\n",
    "    ax[col, row].set_xlabel('Recall')\n",
    "    ax[col, row].set_ylabel('Precision')\n",
    "    ax[col, row].set_xlim(-0.05, 1.05)\n",
    "    ax[col, row].set_xticks([0.0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "    ax[col, row].set_ylim(0, 1.05)\n",
    "    ax[col, row].set_yticks([0.00, 0.25, 0.50, 0.75, 1.00])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linestyle_list = ['solid', 'dashed', 'dotted', 'dashdot', 'solid', 'dashed', 'dotted', 'dashdot']\n",
    "color_list = ['black', 'black', 'black', 'black', 'grey', 'grey', 'grey', 'grey']\n",
    "ax = plt.gca()\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(8, 4)\n",
    "fig.set_dpi(dpi_high)\n",
    "for i in range(0, int(len(log_reg_means_list))):\n",
    "    log_reg_display = PrecisionRecallDisplay.from_estimator(log_reg_models[i], X_list[i][1], y_list[i][1], name=f'Logistic Regression {name_list[i]}', \n",
    "                                                            color=color_list[i], linestyle=linestyle_list[i], ax=plt.gca())\n",
    "ax.set_title(\"Logistic Regression Combined Precision-Recall curve\")\n",
    "ax.legend(loc='best', prop={'size': 8})\n",
    "ax.set_xlabel('Recall')\n",
    "ax.set_ylabel('Precision')\n",
    "ax.set_xlim(-0.05, 1.05)\n",
    "ax.set_ylim(0, 1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(8, 4)\n",
    "fig.set_dpi(dpi_high)\n",
    "for i in range(0, 4):\n",
    "    log_reg_display = PrecisionRecallDisplay.from_estimator(log_reg_models[i], X_list[i][1], y_list[i][1], name=f'Logistic Regression {name_list[i]}', \n",
    "                                                            color=color_list[i], linestyle=linestyle_list[i], ax=plt.gca())\n",
    "ax.set_title(\"Logistic Regression Combined Precision-Recall curve\")\n",
    "ax.legend(loc='best', prop={'size': 8})\n",
    "ax.set_xlabel('Recall')\n",
    "ax.set_ylabel('Precision')\n",
    "ax.set_xlim(-0.05, 1.05)\n",
    "ax.set_ylim(0, 1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(8, 4)\n",
    "fig.set_dpi(dpi_high)\n",
    "for i in range(4, int(len(log_reg_means_list))):\n",
    "    log_reg_display = PrecisionRecallDisplay.from_estimator(log_reg_models[i], X_list[i][1], y_list[i][1], name=f'Logistic Regression {name_list[i]}', \n",
    "                                                            color=color_list[i], linestyle=linestyle_list[i], ax=plt.gca())\n",
    "ax.set_title(\"Logistic Regression Combined Precision-Recall curve\")\n",
    "ax.legend(loc='best', prop={'size': 8})\n",
    "ax.set_xlabel('Recall')\n",
    "ax.set_ylabel('Precision')\n",
    "ax.set_xlim(-0.05, 1.05)\n",
    "ax.set_ylim(0, 1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(8, 4)\n",
    "fig.set_dpi(dpi_high)\n",
    "for i in range(0, int(len(log_reg_means_list))):\n",
    "    log_reg_display = RocCurveDisplay.from_estimator(log_reg_models[i], X_list[i][1], y_list[i][1], name=f'Logistic Regression {name_list[i]}', \n",
    "                                                            color=color_list[i], linestyle=linestyle_list[i], ax=plt.gca())\n",
    "ax.set_title(\"Logistic Regression Combined AUROC\")\n",
    "ax.legend(loc='best', prop={'size': 8})\n",
    "ax.set_xlabel('Recall')\n",
    "ax.set_ylabel('Precision')\n",
    "ax.set_xlim(-0.05, 1.05)\n",
    "ax.set_ylim(0, 1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(8, 4)\n",
    "fig.set_dpi(dpi_high)\n",
    "for i in range(0, 4):\n",
    "    log_reg_display = RocCurveDisplay.from_estimator(log_reg_models[i], X_list[i][1], y_list[i][1], name=f'Logistic Regression {name_list[i]}', \n",
    "                                                            color=color_list[i], linestyle=linestyle_list[i], ax=plt.gca())\n",
    "ax.set_title(\"Logistic Regression Combined AUROC\")\n",
    "ax.legend(loc='best', prop={'size': 8})\n",
    "ax.set_xlabel('Recall')\n",
    "ax.set_ylabel('Precision')\n",
    "ax.set_xlim(-0.05, 1.05)\n",
    "ax.set_ylim(0, 1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(8, 4)\n",
    "fig.set_dpi(dpi_high)\n",
    "for i in range(4, int(len(log_reg_means_list))):\n",
    "    log_reg_display = RocCurveDisplay.from_estimator(log_reg_models[i], X_list[i][1], y_list[i][1], name=f'Logistic Regression {name_list[i]}', \n",
    "                                                            color=color_list[i], linestyle=linestyle_list[i], ax=plt.gca())\n",
    "ax.set_title(\"Logistic Regression Combined AUROC\")\n",
    "ax.legend(loc='best', prop={'size': 8})\n",
    "ax.set_xlabel('Recall')\n",
    "ax.set_ylabel('Precision')\n",
    "ax.set_xlim(-0.05, 1.05)\n",
    "ax.set_ylim(0, 1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot confusion matrix for each classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_list = []\n",
    "heat_map_list = []\n",
    "\n",
    "temp_conf_mat = []\n",
    "temp_heat_map = []\n",
    "for i in range(0, int(len(log_reg_means_list))):\n",
    "    conf_mat = confusion_matrix(y_list[i][1], log_reg_test_prediction[i])\n",
    "    temp_conf_mat.append(conf_mat)\n",
    "    heat = pd.DataFrame(conf_mat, columns=np.unique(y_list[i][1]), index=np.unique(y_list[i][1]))\n",
    "    heat.index.name = 'Actual'\n",
    "    heat.columns.name = 'Predicted'\n",
    "    temp_heat_map.append(heat)\n",
    "\n",
    "confusion_matrix_list.append(temp_conf_mat)\n",
    "heat_map_list.append(temp_heat_map)\n",
    "\n",
    "fig, ax = plt.subplots(int(len(log_reg_means_list)/4), 4, figsize=(20, 18))\n",
    "fig.subplots_adjust(left=None, bottom=None, right=2, top=None, wspace=None, hspace=0.3)\n",
    "\n",
    "sns.set(font_scale=1.4)\n",
    "lc = 'Grey'\n",
    "lw = 1\n",
    "col = -1\n",
    "row = 0\n",
    "for i in range(int(len(log_reg_means_list))):\n",
    "    if i % 4 == 0:\n",
    "        col += 1\n",
    "        row = 0\n",
    "    else:\n",
    "        row += 1\n",
    "    \n",
    "    sns.heatmap(heat_map_list[-1][i], cmap='Greys', annot=True, annot_kws={'size': 16}, fmt='g', ax=ax[col, row], xticklabels=label, yticklabels=label, linecolor=lc, linewidths=lw)\n",
    "    ax[col, row].set_title(('Logistic Regression '+name_list[i]), fontweight='bold')\n",
    "sns.set(font_scale=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rc_file_defaults()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save output for model persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Model 1': [], 'Model 2': [], 'Model 3': [], 'Model 4': [], 'Model 5': [], 'Model 6': [], 'Model 7': [], 'Model 8': []}\n",
    "for i, model in enumerate(data):\n",
    "    data[model].append(log_reg_means_list[i])\n",
    "    data[model].append(log_reg_params_list[i])\n",
    "    data[model].append(log_reg_best_result_list[i])\n",
    "    data[model].append(log_reg_best_C[i])\n",
    "    data[model].append(log_reg_best_penalty[i])\n",
    "    data[model].append(log_reg_best_solver[i])\n",
    "    data[model].append(log_reg_best_intercept[i])\n",
    "    dump(log_reg_models[i], f'models/output-log-reg{i}.joblib')\n",
    "    data[model].append(log_reg_accuracy[i])\n",
    "    data[model].append(log_reg_precision[i])\n",
    "    data[model].append(log_reg_recall[i])\n",
    "    data[model].append(log_reg_f1[i])\n",
    "    data[model].append(log_reg_classification_report[i])\n",
    "    data[model].append(log_reg_test_prediction[i])\n",
    "    data[model].append(log_reg_pr[i])\n",
    "    data[model].append(heat_map_list[0][i])\n",
    "    \n",
    "output_df = pd.DataFrame(data)\n",
    "index_list = ['log_reg_means_list','log_reg_params_list','log_reg_best_result_list','log_reg_best_C','log_reg_best_penalty','log_reg_best_solver','log_reg_best_intercept','log_reg_accuracy',\n",
    "              'log_reg_precision','log_reg_recall','log_reg_f1','log_reg_classification_report','log_reg_test_prediction','log_reg_pr','heat_map_log_reg']\n",
    "output_df.insert(0, 'Name', index_list)\n",
    "output_df.set_index(output_df['Name'], inplace=True)\n",
    "output_df.drop('Name', axis=1, inplace=True)\n",
    "dump(output_df, 'models/output-log-reg.joblib')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aef203514c858290544fd6a14248b5f64855080360fc299c24eb5474b48fd873"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
