{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master Thesis: Bankruptcy Prediction for European Countries\n",
    "Code written by Marc Zeugin (UZH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report, PrecisionRecallDisplay, confusion_matrix, RocCurveDisplay\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearnex.ensemble import RandomForestClassifier\n",
    "from sklearnex.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import IterativeImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.combine import SMOTEENN\n",
    "from skopt.space import Real, Integer\n",
    "from matplotlib import pyplot as plt\n",
    "from lightgbm import LGBMClassifier\n",
    "from skopt import BayesSearchCV\n",
    "from joblib import dump, Memory\n",
    "from sklearnex.svm import SVC\n",
    "from itertools import product\n",
    "from tempfile import mkdtemp\n",
    "from shutil import rmtree\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "import pyarrow\n",
    "import glob\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup key variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine training/testing ratio, default is 0.2\n",
    "tt_size = 0.2\n",
    "# number of splits for k-fold crossvalidation, default is 5\n",
    "k_splits = 5\n",
    "# set number of jobs to run in parallel, -1 means all processors, default is 1\n",
    "jobs = -1\n",
    "# number of iterations for BayesSearchCV\n",
    "n_iterations = 40\n",
    "# select scoring model to optimize, default is average_precision, the value used for the precision-recall curve\n",
    "scoring_metric = 'average_precision'\n",
    "# label for classification report\n",
    "label = ['Non-Bankrupt', 'Bankrupt']\n",
    "\n",
    "# absolute path to dataset\n",
    "path = 'C:/Users/marczeugin/Documents/Masterthesis/datasets/'\n",
    "# extension of dataset type\n",
    "ext = '*.csv'\n",
    "\n",
    "# determine the size (in inches) of the precision-recall curve figure, default is (4, 2)\n",
    "figure_size = (4, 2)\n",
    "# set dpi of small graphs, default is 100\n",
    "dpi_low = 100\n",
    "# set dpi of medium graphs, default is 200\n",
    "dpi_med = 200\n",
    "# set dpi of large graphs, default is 250\n",
    "dpi_high = 250\n",
    "\n",
    "# enable subsample of total dataset to be used for hyperparameter tuning, default is True\n",
    "allow_subsample = True\n",
    "# set subsample size of total dataset, default is .1 e.g. 10%\n",
    "subsample_size = 0.1\n",
    "# enable quick overview to run with subsample\n",
    "allow_subsample_overview = True\n",
    "# enable hyperparameter tuning with subsample\n",
    "allow_subsample_hyperparameter = True\n",
    "\n",
    "# allow to load dataset with SMOTEENN already run and imputation already imputed, default is True\n",
    "allow_computed_set = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create model lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list = ['complete', 'without years', 'without macro', 'without years and macro', 'complete SMOTEENN', 'without years SMOTEENN', 'without macro SMOTEENN', 'without years and macro SMOTEENN']\n",
    "\n",
    "X_list = np.load('X_list.npy', allow_pickle=True).tolist()\n",
    "X_list_m = np.load('X_list_m.npy', allow_pickle=True).tolist()\n",
    "y_list = np.load('y_list.npy', allow_pickle=True).tolist()\n",
    "y_list_m = np.load('y_list_m.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.11. Hyperparameter tuning for LGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.11.1. Without SMOTEENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_list_lgbm = dict()\n",
    "params_list_lgbm['n_estimators'] = Integer(10, 4000)\n",
    "params_list_lgbm['num_leaves'] = Integer(6, 100)\n",
    "params_list_lgbm['max_depth'] = Integer(1, 25)\n",
    "params_list_lgbm['min_data'] = Integer(100, 4000)\n",
    "model = LGBMClassifier(random_state=1, n_jobs=jobs, class_weight='balanced')\n",
    "kfold = StratifiedKFold(n_splits=k_splits, random_state=1, shuffle=True)\n",
    "grid = BayesSearchCV(estimator=model, search_spaces=params_list_lgbm, scoring=scoring_metric, cv=kfold, error_score=0, random_state=1, n_jobs=jobs, n_iter=n_iterations)\n",
    "fig_cols = 2\n",
    "fig_rows = 4\n",
    "\n",
    "lgbm_means_list = []\n",
    "lgbm_names_list = []\n",
    "lgbm_params_list = []\n",
    "lgbm_best_result_list = []\n",
    "lgbm_max_means_list = []\n",
    "lgbm_num_leaves = []\n",
    "lgbm_n_estimator = []\n",
    "lgbm_max_depth = []\n",
    "lgbm_min_data_in_leaf = []\n",
    "\n",
    "for i in range(0, int(len(X_list_m))):\n",
    "    grid_result = grid.fit(X_list_m[i][0], y_list_m[i][0])\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    \n",
    "    lgbm_names = []\n",
    "    for k in range(len(params)):\n",
    "        new_string = str(params[k]['num_leaves']) + ' ' + str(params[k]['n_estimators']) + ' ' + str(params[k]['max_depth']) + ' ' + str(params[k]['min_data'])\n",
    "        lgbm_names.append(new_string)\n",
    "    \n",
    "    index_to_rm = []\n",
    "    for index, item in enumerate(params):\n",
    "        if item in params[:index]:\n",
    "            index_to_rm.append(index)\n",
    "    means = np.delete(means, index_to_rm)\n",
    "    lgbm_names = np.delete(lgbm_names, index_to_rm)\n",
    "    params = np.delete(params, index_to_rm)\n",
    "    max_mean = np.argmax(means)\n",
    "    \n",
    "    lgbm_means_list.append(means)\n",
    "    lgbm_names_list.append(lgbm_names)\n",
    "    lgbm_params_list.append(params)\n",
    "    lgbm_max_means_list.append(max_mean)\n",
    "    lgbm_best_result_list.append(grid_result.best_score_)\n",
    "    \n",
    "    print(f'Best {scoring_metric} of {round(grid_result.best_score_,4)} for num leaves of {grid_result.best_params_[\"num_leaves\"]}, number of estimators of {grid_result.best_params_[\"n_estimators\"]}, max depth of {grid_result.best_params_[\"max_depth\"]}, and min data in leaf of {grid_result.best_params_[\"min_data\"]}')\n",
    "    \n",
    "    lgbm_num_leaves.append(grid_result.best_params_[\"num_leaves\"])\n",
    "    lgbm_n_estimator.append(grid_result.best_params_[\"n_estimators\"])\n",
    "    lgbm_max_depth.append(grid_result.best_params_[\"max_depth\"])\n",
    "    lgbm_min_data_in_leaf.append(grid_result.best_params_[\"min_data\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.11.2. With SMOTEENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cachedir = mkdtemp()\n",
    "memory = Memory(cachedir=cachedir, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_list_lgbm_smoteenn = dict()\n",
    "params_list_lgbm_smoteenn['model__n_estimators'] = Integer(10, 4000)\n",
    "params_list_lgbm_smoteenn['model__num_leaves'] = Integer(6, 50)\n",
    "params_list_lgbm_smoteenn['model__max_depth'] = Integer(1, 25)\n",
    "params_list_lgbm_smoteenn['model__min_data'] = Integer(100, 4000)\n",
    "pipe = Pipeline([('SMOTEENN', SMOTEENN(smote=SMOTE(sampling_strategy='minority', random_state=1), enn=EditedNearestNeighbours(sampling_strategy='all'), \n",
    "                                       random_state=1, n_jobs=jobs)), ('model', LGBMClassifier(random_state=1, n_jobs=jobs))], memory=memory)\n",
    "kfold = StratifiedKFold(n_splits=k_splits, random_state=1, shuffle=True)\n",
    "grid = BayesSearchCV(estimator=pipe, search_spaces=params_list_lgbm_smoteenn, scoring=scoring_metric, cv=kfold, error_score=0, random_state=1, n_jobs=jobs, n_iter=n_iterations)\n",
    "fig_cols = 2\n",
    "fig_rows = 4\n",
    "\n",
    "for i in range(0, int(len(X_list_m))):\n",
    "    grid_result = grid.fit(X_list_m[i][0], y_list_m[i][0])\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    \n",
    "    lgbm_names = []\n",
    "    for k in range(len(params)):\n",
    "        new_string = str(params[k]['model__num_leaves']) + ' ' + str(params[k]['model__n_estimators']) + ' ' + str(params[k]['model__max_depth']) + ' ' + str(params[k]['model__min_data'])\n",
    "        lgbm_names.append(new_string)\n",
    "    \n",
    "    index_to_rm = []\n",
    "    for index, item in enumerate(params):\n",
    "        if item in params[:index]:\n",
    "            index_to_rm.append(index)\n",
    "    means = np.delete(means, index_to_rm)\n",
    "    lgbm_names = np.delete(lgbm_names, index_to_rm)\n",
    "    params = np.delete(params, index_to_rm)\n",
    "    max_mean = np.argmax(means)\n",
    "    \n",
    "    lgbm_means_list.append(means)\n",
    "    lgbm_names_list.append(lgbm_names)\n",
    "    lgbm_params_list.append(params)\n",
    "    lgbm_max_means_list.append(max_mean)\n",
    "    lgbm_best_result_list.append(grid_result.best_score_)\n",
    "    \n",
    "    print(f'Best {scoring_metric} of {round(grid_result.best_score_,4)} for num leaves of {grid_result.best_params_[\"model__num_leaves\"]}, number of estimators of {grid_result.best_params_[\"model__n_estimators\"]}, \\\n",
    "          max depth of {grid_result.best_params_[\"model__max_depth\"]}, and min data in leaf of {grid_result.best_params_[\"model__min_data\"]}')\n",
    "    \n",
    "    lgbm_num_leaves.append(grid_result.best_params_[\"model__num_leaves\"])\n",
    "    lgbm_n_estimator.append(grid_result.best_params_[\"model__n_estimators\"])\n",
    "    lgbm_max_depth.append(grid_result.best_params_[\"model__max_depth\"])\n",
    "    lgbm_min_data_in_leaf.append(grid_result.best_params_[\"model__min_data\"])\n",
    "    \n",
    "rmtree(cachedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = -1\n",
    "row = 0\n",
    "\n",
    "fig, ax = plt.subplots(4, 2)\n",
    "fig.set_size_inches((30, 30))\n",
    "fig.tight_layout(h_pad=20.0, w_pad=4)\n",
    "fig.set_dpi(dpi_low)\n",
    "for i in range(0, 8):\n",
    "    if i % 2 == 0:\n",
    "        col += 1\n",
    "        row = 0\n",
    "    if i % 2 == 1:\n",
    "        row += 1\n",
    "        \n",
    "    ax[col, row].plot(range(len(lgbm_names_list[i])), lgbm_means_list[i], color='grey', marker='o', markerfacecolor='black')\n",
    "    ax[col, row].plot(lgbm_max_means_list[i], lgbm_best_result_list[i], marker='o', markerfacecolor='red', markeredgecolor=\"red\")\n",
    "    ax[col, row].set_title(f'Mean {scoring_metric} for LGBM with stratified {k_splits}-fold crossvalidation\\n{name_list[i]}')\n",
    "    ax[col, row].set_xticks(range(len(lgbm_names_list[i])))\n",
    "    ax[col, row].set_xticklabels(lgbm_names_list[i], rotation=45, ha='right')\n",
    "    ax[col, row].set_xlabel('LGBM Hyperparameters (Num leaves, n estimators, max depth, and min data in leaf)')\n",
    "    ax[col, row].set_ylabel(scoring_metric)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.12. LGBM with optimal hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_models = []\n",
    "lgbm_accuracy = []\n",
    "lgbm_precision = []\n",
    "lgbm_recall = []\n",
    "lgbm_f1 = []\n",
    "lgbm_classification_report = []\n",
    "lgbm_test_prediction = []\n",
    "\n",
    "for i, variant in enumerate(X_list):\n",
    "    lgbm = LGBMClassifier(random_seed=1, class_weight='balanced', n_jobs=jobs, max_depth=lgbm_max_depth[i], n_estimators=lgbm_n_estimator[i], num_leaves=lgbm_num_leaves[i], min_data=lgbm_min_data_in_leaf[i])\n",
    "    lgbm.fit(variant[0], y_list[i][0])\n",
    "    lgbm_test_pred = lgbm.predict(variant[1])\n",
    "    lgbm_test_prediction.append(lgbm_test_pred)\n",
    "\n",
    "    lgbm_accuracy.append(lgbm.score(variant[1], y_list[i][1]))\n",
    "    lgbm_precision.append(precision_score(y_list[i][1], lgbm_test_pred))\n",
    "    lgbm_recall.append(recall_score(y_list[i][1], lgbm_test_pred))\n",
    "    lgbm_f1.append(f1_score(y_list[i][1], lgbm_test_pred))\n",
    "\n",
    "    lgbm_classification_report.append(classification_report(y_list[i][1], lgbm_test_pred, target_names=label))\n",
    "\n",
    "    lgbm_models.append(lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_pr = []\n",
    "\n",
    "fig, ax = plt.subplots(4, 2)\n",
    "fig.set_size_inches((20, 15))\n",
    "fig.tight_layout(pad=5.0)\n",
    "col = -1\n",
    "row = 0\n",
    "for i in range(0, 8):\n",
    "    if i % 2 == 0:\n",
    "        col += 1\n",
    "        row = 0\n",
    "    elif i % 2 == 1:\n",
    "        row += 1\n",
    "    \n",
    "    lgbm_display = PrecisionRecallDisplay.from_estimator(lgbm_models[i], X_list[i][1], y_list[i][1], name='LGBM', color='black', ax=ax[col, row])\n",
    "    lgbm_pr.append(lgbm_display)\n",
    "    ax[col, row].set_title('LGBM Precision-Recall curve ' + name_list[i], fontweight='bold')\n",
    "    ax[col, row].legend(loc='best')\n",
    "    ax[col, row].set_xlabel('Recall')\n",
    "    ax[col, row].set_ylabel('Precision')\n",
    "    ax[col, row].set_xlim(-0.05, 1.05)\n",
    "    ax[col, row].set_xticks([0.0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "    ax[col, row].set_ylim(0, 1.05)\n",
    "    ax[col, row].set_yticks([0.00, 0.25, 0.50, 0.75, 1.00])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linestyle_list = ['solid', 'dashed', 'dotted', 'dashdot', 'solid', 'dashed', 'dotted', 'dashdot']\n",
    "color_list = ['black', 'black', 'black', 'black', 'grey', 'grey', 'grey', 'grey']\n",
    "\n",
    "ax = plt.gca()\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(8, 4)\n",
    "fig.set_dpi(dpi_high)\n",
    "for i in range(0, int(len(lgbm_means_list))):\n",
    "    lgbm_display = PrecisionRecallDisplay.from_estimator(lgbm_models[i], X_list[i][1], y_list[i][1], name=f'LGBM {name_list[i]}', \n",
    "                                                            color=color_list[i], linestyle=linestyle_list[i], ax=plt.gca())\n",
    "ax.set_title(\"LGBM Combined Precision-Recall curve\")\n",
    "ax.legend(loc='best', prop={'size': 8})\n",
    "ax.set_xlabel('Recall')\n",
    "ax.set_ylabel('Precision')\n",
    "ax.set_xlim(-0.05, 1.05)\n",
    "ax.set_ylim(0, 1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(8, 4)\n",
    "fig.set_dpi(dpi_high)\n",
    "for i in range(0, 4):\n",
    "    lgbm_display = PrecisionRecallDisplay.from_estimator(lgbm_models[i], X_list[i][1], y_list[i][1], name=f'LGBM {name_list[i]}', \n",
    "                                                            color=color_list[i], linestyle=linestyle_list[i], ax=plt.gca())\n",
    "ax.set_title(\"LGBM Combined Precision-Recall curve\")\n",
    "ax.legend(loc='best', prop={'size': 8})\n",
    "ax.set_xlabel('Recall')\n",
    "ax.set_ylabel('Precision')\n",
    "ax.set_xlim(-0.05, 1.05)\n",
    "ax.set_ylim(0, 1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(8, 4)\n",
    "fig.set_dpi(dpi_high)\n",
    "for i in range(4, int(len(lgbm_means_list))):\n",
    "    lgbm_display = PrecisionRecallDisplay.from_estimator(lgbm_models[i], X_list[i][1], y_list[i][1], name=f'LGBM {name_list[i]}', \n",
    "                                                            color=color_list[i], linestyle=linestyle_list[i], ax=plt.gca())\n",
    "ax.set_title(\"LGBM Combined Precision-Recall curve\")\n",
    "ax.legend(loc='best', prop={'size': 8})\n",
    "ax.set_xlabel('Recall')\n",
    "ax.set_ylabel('Precision')\n",
    "ax.set_xlim(-0.05, 1.05)\n",
    "ax.set_ylim(0, 1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(8, 4)\n",
    "fig.set_dpi(dpi_high)\n",
    "for i in range(0, int(len(lgbm_means_list))):\n",
    "    lgbm_display = RocCurveDisplay.from_estimator(lgbm_models[i], X_list[i][1], y_list[i][1], name=f'LGBM {name_list[i]}', \n",
    "                                                            color=color_list[i], linestyle=linestyle_list[i], ax=plt.gca())\n",
    "ax.set_title(\"LGBM Combined AUROC\")\n",
    "ax.legend(loc='best', prop={'size': 8})\n",
    "ax.set_xlabel('Recall')\n",
    "ax.set_ylabel('Precision')\n",
    "ax.set_xlim(-0.05, 1.05)\n",
    "ax.set_ylim(0, 1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(8, 4)\n",
    "fig.set_dpi(dpi_high)\n",
    "for i in range(0, 4):\n",
    "    lgbm_display = RocCurveDisplay.from_estimator(lgbm_models[i], X_list[i][1], y_list[i][1], name=f'LGBM {name_list[i]}', \n",
    "                                                            color=color_list[i], linestyle=linestyle_list[i], ax=plt.gca())\n",
    "ax.set_title(\"LGBM Combined AUROC\")\n",
    "ax.legend(loc='best', prop={'size': 8})\n",
    "ax.set_xlabel('Recall')\n",
    "ax.set_ylabel('Precision')\n",
    "ax.set_xlim(-0.05, 1.05)\n",
    "ax.set_ylim(0, 1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(8, 4)\n",
    "fig.set_dpi(dpi_high)\n",
    "for i in range(4, int(len(lgbm_means_list))):\n",
    "    lgbm_display = RocCurveDisplay.from_estimator(lgbm_models[i], X_list[i][1], y_list[i][1], name=f'LGBM {name_list[i]}', \n",
    "                                                            color=color_list[i], linestyle=linestyle_list[i], ax=plt.gca())\n",
    "ax.set_title(\"LGBM Combined AUROC\")\n",
    "ax.legend(loc='best', prop={'size': 8})\n",
    "ax.set_xlabel('Recall')\n",
    "ax.set_ylabel('Precision')\n",
    "ax.set_xlim(-0.05, 1.05)\n",
    "ax.set_ylim(0, 1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot confusion matrix for each classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_list = []\n",
    "heat_map_list = []\n",
    "\n",
    "temp_conf_mat = []\n",
    "temp_heat_map = []\n",
    "for i in range(0, int(len(lgbm_means_list))):\n",
    "    conf_mat = confusion_matrix(y_list[i][1], lgbm_test_prediction[i])\n",
    "    temp_conf_mat.append(conf_mat)\n",
    "    heat = pd.DataFrame(conf_mat, columns=np.unique(y_list[i][1]), index=np.unique(y_list[i][1]))\n",
    "    heat.index.name = 'Actual'\n",
    "    heat.columns.name = 'Predicted'\n",
    "    temp_heat_map.append(heat)\n",
    "\n",
    "confusion_matrix_list.append(temp_conf_mat)\n",
    "heat_map_list.append(temp_heat_map)\n",
    "\n",
    "fig, ax = plt.subplots(int(len(lgbm_means_list)/4), 4, figsize=(20, 18))\n",
    "fig.subplots_adjust(left=None, bottom=None, right=2, top=None, wspace=None, hspace=0.3)\n",
    "\n",
    "sns.set(font_scale=1.4)\n",
    "lc = 'Grey'\n",
    "lw = 1\n",
    "col = -1\n",
    "row = 0\n",
    "for i in range(int(len(lgbm_means_list))):\n",
    "    if i % 4 == 0:\n",
    "        col += 1\n",
    "        row = 0\n",
    "    else:\n",
    "        row += 1\n",
    "    \n",
    "    sns.heatmap(heat_map_list[-1][i], cmap='Greys', annot=True, annot_kws={'size': 16}, fmt='g', ax=ax[col, row], xticklabels=label, yticklabels=label, linecolor=lc, linewidths=lw)\n",
    "    ax[col, row].set_title(('LGBM '+name_list[i]), fontweight='bold')\n",
    "sns.set(font_scale=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rc_file_defaults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Model 1': [], 'Model 2': [], 'Model 3': [], 'Model 4': [], 'Model 5': [], 'Model 6': [], 'Model 7': [], 'Model 8': []}\n",
    "for i, model in enumerate(data):\n",
    "    data[model].append(lgbm_means_list[i])\n",
    "    data[model].append(lgbm_params_list[i])\n",
    "    data[model].append(lgbm_best_result_list[i])\n",
    "    data[model].append(lgbm_num_leaves[i])\n",
    "    data[model].append(lgbm_n_estimator[i])\n",
    "    data[model].append(lgbm_max_depth[i])\n",
    "    data[model].append(lgbm_min_data_in_leaf[i])\n",
    "    dump(lgbm_models[i], f'models/output-lgbm{i}.joblib')\n",
    "    data[model].append(lgbm_accuracy[i])\n",
    "    data[model].append(lgbm_precision[i])\n",
    "    data[model].append(lgbm_recall[i])\n",
    "    data[model].append(lgbm_f1[i])\n",
    "    data[model].append(lgbm_classification_report[i])\n",
    "    data[model].append(lgbm_test_prediction[i])\n",
    "    data[model].append(lgbm_pr[i])\n",
    "    data[model].append(heat_map_list[0][i])\n",
    "    \n",
    "output_df = pd.DataFrame(data)\n",
    "index_list = ['lgbm_means_list','lgbm_params_list','lgbm_best_result_list','lgbm_best_num_leaves','lgbm_best_n_estimator','lgbm_best_max_depth','lgbm_best_min_data_in_leaf','lgbm_accuracy',\n",
    "              'lgbm_precision','lgbm_recall','lgbm_f1','lgbm_classification_report','lgbm_test_prediction','lgbm_pr','heat_map_lgbm']\n",
    "output_df.insert(0, 'Name', index_list)\n",
    "output_df.set_index(output_df['Name'], inplace=True)\n",
    "output_df.drop('Name', axis=1, inplace=True)\n",
    "dump(output_df, 'models/output-lgbm.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.12a. LGBM without optimal hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_models = []\n",
    "lgbm_accuracy = []\n",
    "lgbm_precision = []\n",
    "lgbm_recall = []\n",
    "lgbm_f1 = []\n",
    "lgbm_classification_report = []\n",
    "lgbm_test_prediction = []\n",
    "\n",
    "for i, variant in enumerate(X_list):\n",
    "    lgbm = LGBMClassifier(random_seed=1, class_weight='balanced', n_jobs=jobs)\n",
    "    lgbm.fit(variant[0], y_list[i][0])\n",
    "    lgbm_test_pred = lgbm.predict(variant[1])\n",
    "    lgbm_test_prediction.append(lgbm_test_pred)\n",
    "\n",
    "    lgbm_accuracy.append(lgbm.score(variant[1], y_list[i][1]))\n",
    "    lgbm_precision.append(precision_score(y_list[i][1], lgbm_test_pred))\n",
    "    lgbm_recall.append(recall_score(y_list[i][1], lgbm_test_pred))\n",
    "    lgbm_f1.append(f1_score(y_list[i][1], lgbm_test_pred))\n",
    "\n",
    "    lgbm_classification_report.append(classification_report(y_list[i][1], lgbm_test_pred, target_names=label))\n",
    "\n",
    "    lgbm_models.append(lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_pr = []\n",
    "\n",
    "fig, ax = plt.subplots(4, 2)\n",
    "fig.set_size_inches((20, 15))\n",
    "fig.tight_layout(pad=5.0)\n",
    "col = -1\n",
    "row = 0\n",
    "for i in range(0, 8):\n",
    "    if i % 2 == 0:\n",
    "        col += 1\n",
    "        row = 0\n",
    "    elif i % 2 == 1:\n",
    "        row += 1\n",
    "    \n",
    "    lgbm_display = PrecisionRecallDisplay.from_estimator(lgbm_models[i], X_list[i][1], y_list[i][1], name='LGBM', color='black', ax=ax[col, row])\n",
    "    lgbm_pr.append(lgbm_display)\n",
    "    ax[col, row].set_title('LGBM Precision-Recall curve ' + name_list[i], fontweight='bold')\n",
    "    ax[col, row].legend(loc='best')\n",
    "    ax[col, row].set_xlabel('Recall')\n",
    "    ax[col, row].set_ylabel('Precision')\n",
    "    ax[col, row].set_xlim(-0.05, 1.05)\n",
    "    ax[col, row].set_xticks([0.0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "    ax[col, row].set_ylim(0, 1.05)\n",
    "    ax[col, row].set_yticks([0.00, 0.25, 0.50, 0.75, 1.00])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linestyle_list = ['solid', 'dashed', 'dotted', 'dashdot', 'solid', 'dashed', 'dotted', 'dashdot']\n",
    "color_list = ['black', 'black', 'black', 'black', 'grey', 'grey', 'grey', 'grey']\n",
    "\n",
    "ax = plt.gca()\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(8, 4)\n",
    "fig.set_dpi(dpi_high)\n",
    "for i in range(0, int(len(lgbm_means_list))):\n",
    "    lgbm_display = PrecisionRecallDisplay.from_estimator(lgbm_models[i], X_list[i][1], y_list[i][1], name=f'LGBM {name_list[i]}', \n",
    "                                                            color=color_list[i], linestyle=linestyle_list[i], ax=plt.gca())\n",
    "ax.set_title(\"LGBM Combined Precision-Recall curve\")\n",
    "ax.legend(loc='best', prop={'size': 8})\n",
    "ax.set_xlabel('Recall')\n",
    "ax.set_ylabel('Precision')\n",
    "ax.set_xlim(-0.05, 1.05)\n",
    "ax.set_ylim(0, 1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(8, 4)\n",
    "fig.set_dpi(dpi_high)\n",
    "for i in range(0, 4):\n",
    "    lgbm_display = PrecisionRecallDisplay.from_estimator(lgbm_models[i], X_list[i][1], y_list[i][1], name=f'LGBM {name_list[i]}', \n",
    "                                                            color=color_list[i], linestyle=linestyle_list[i], ax=plt.gca())\n",
    "ax.set_title(\"LGBM Combined Precision-Recall curve\")\n",
    "ax.legend(loc='best', prop={'size': 8})\n",
    "ax.set_xlabel('Recall')\n",
    "ax.set_ylabel('Precision')\n",
    "ax.set_xlim(-0.05, 1.05)\n",
    "ax.set_ylim(0, 1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(8, 4)\n",
    "fig.set_dpi(dpi_high)\n",
    "for i in range(4, int(len(lgbm_means_list))):\n",
    "    lgbm_display = PrecisionRecallDisplay.from_estimator(lgbm_models[i], X_list[i][1], y_list[i][1], name=f'LGBM {name_list[i]}', \n",
    "                                                            color=color_list[i], linestyle=linestyle_list[i], ax=plt.gca())\n",
    "ax.set_title(\"LGBM Combined Precision-Recall curve\")\n",
    "ax.legend(loc='best', prop={'size': 8})\n",
    "ax.set_xlabel('Recall')\n",
    "ax.set_ylabel('Precision')\n",
    "ax.set_xlim(-0.05, 1.05)\n",
    "ax.set_ylim(0, 1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(8, 4)\n",
    "fig.set_dpi(dpi_high)\n",
    "for i in range(0, int(len(lgbm_means_list))):\n",
    "    lgbm_display = RocCurveDisplay.from_estimator(lgbm_models[i], X_list[i][1], y_list[i][1], name=f'LGBM {name_list[i]}', \n",
    "                                                            color=color_list[i], linestyle=linestyle_list[i], ax=plt.gca())\n",
    "ax.set_title(\"LGBM Combined AUROC\")\n",
    "ax.legend(loc='best', prop={'size': 8})\n",
    "ax.set_xlabel('Recall')\n",
    "ax.set_ylabel('Precision')\n",
    "ax.set_xlim(-0.05, 1.05)\n",
    "ax.set_ylim(0, 1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(8, 4)\n",
    "fig.set_dpi(dpi_high)\n",
    "for i in range(0, 4):\n",
    "    lgbm_display = RocCurveDisplay.from_estimator(lgbm_models[i], X_list[i][1], y_list[i][1], name=f'LGBM {name_list[i]}', \n",
    "                                                            color=color_list[i], linestyle=linestyle_list[i], ax=plt.gca())\n",
    "ax.set_title(\"LGBM Combined AUROC\")\n",
    "ax.legend(loc='best', prop={'size': 8})\n",
    "ax.set_xlabel('Recall')\n",
    "ax.set_ylabel('Precision')\n",
    "ax.set_xlim(-0.05, 1.05)\n",
    "ax.set_ylim(0, 1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(8, 4)\n",
    "fig.set_dpi(dpi_high)\n",
    "for i in range(4, int(len(lgbm_means_list))):\n",
    "    lgbm_display = RocCurveDisplay.from_estimator(lgbm_models[i], X_list[i][1], y_list[i][1], name=f'LGBM {name_list[i]}', \n",
    "                                                            color=color_list[i], linestyle=linestyle_list[i], ax=plt.gca())\n",
    "ax.set_title(\"LGBM Combined AUROC\")\n",
    "ax.legend(loc='best', prop={'size': 8})\n",
    "ax.set_xlabel('Recall')\n",
    "ax.set_ylabel('Precision')\n",
    "ax.set_xlim(-0.05, 1.05)\n",
    "ax.set_ylim(0, 1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot confusion matrix for each classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_list = []\n",
    "heat_map_list = []\n",
    "\n",
    "temp_conf_mat = []\n",
    "temp_heat_map = []\n",
    "for i in range(0, int(len(lgbm_means_list))):\n",
    "    conf_mat = confusion_matrix(y_list[i][1], lgbm_test_prediction[i])\n",
    "    temp_conf_mat.append(conf_mat)\n",
    "    heat = pd.DataFrame(conf_mat, columns=np.unique(y_list[i][1]), index=np.unique(y_list[i][1]))\n",
    "    heat.index.name = 'Actual'\n",
    "    heat.columns.name = 'Predicted'\n",
    "    temp_heat_map.append(heat)\n",
    "\n",
    "confusion_matrix_list.append(temp_conf_mat)\n",
    "heat_map_list.append(temp_heat_map)\n",
    "\n",
    "fig, ax = plt.subplots(int(len(lgbm_means_list)/4), 4, figsize=(20, 18))\n",
    "fig.subplots_adjust(left=None, bottom=None, right=2, top=None, wspace=None, hspace=0.3)\n",
    "\n",
    "sns.set(font_scale=1.4)\n",
    "lc = 'Grey'\n",
    "lw = 1\n",
    "col = -1\n",
    "row = 0\n",
    "for i in range(int(len(lgbm_means_list))):\n",
    "    if i % 4 == 0:\n",
    "        col += 1\n",
    "        row = 0\n",
    "    else:\n",
    "        row += 1\n",
    "    \n",
    "    sns.heatmap(heat_map_list[-1][i], cmap='Greys', annot=True, annot_kws={'size': 16}, fmt='g', ax=ax[col, row], xticklabels=label, yticklabels=label, linecolor=lc, linewidths=lw)\n",
    "    ax[col, row].set_title(('LGBM '+name_list[i]), fontweight='bold')\n",
    "sns.set(font_scale=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rc_file_defaults()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save output for model persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Model 1': [], 'Model 2': [], 'Model 3': [], 'Model 4': [], 'Model 5': [], 'Model 6': [], 'Model 7': [], 'Model 8': []}\n",
    "for i, model in enumerate(data):\n",
    "    data[model].append(lgbm_means_list[i])\n",
    "    data[model].append(lgbm_params_list[i])\n",
    "    data[model].append(lgbm_best_result_list[i])\n",
    "    data[model].append(lgbm_num_leaves[i])\n",
    "    data[model].append(lgbm_n_estimator[i])\n",
    "    data[model].append(lgbm_max_depth[i])\n",
    "    data[model].append(lgbm_min_data_in_leaf[i])\n",
    "    dump(lgbm_models[i], f'models/output-lgbm{i}-no-hpt.joblib')\n",
    "    data[model].append(lgbm_accuracy[i])\n",
    "    data[model].append(lgbm_precision[i])\n",
    "    data[model].append(lgbm_recall[i])\n",
    "    data[model].append(lgbm_f1[i])\n",
    "    data[model].append(lgbm_classification_report[i])\n",
    "    data[model].append(lgbm_test_prediction[i])\n",
    "    data[model].append(lgbm_pr[i])\n",
    "    data[model].append(heat_map_list[0][i])\n",
    "    \n",
    "output_df = pd.DataFrame(data)\n",
    "index_list = ['lgbm_means_list','lgbm_params_list','lgbm_best_result_list','lgbm_best_num_leaves','lgbm_best_n_estimator','lgbm_best_max_depth','lgbm_best_min_data_in_leaf','lgbm_accuracy',\n",
    "              'lgbm_precision','lgbm_recall','lgbm_f1','lgbm_classification_report','lgbm_test_prediction','lgbm_pr','heat_map_lgbm']\n",
    "output_df.insert(0, 'Name', index_list)\n",
    "output_df.set_index(output_df['Name'], inplace=True)\n",
    "output_df.drop('Name', axis=1, inplace=True)\n",
    "dump(output_df, 'models/output-lgbm-no-hpt.joblib')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aef203514c858290544fd6a14248b5f64855080360fc299c24eb5474b48fd873"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
