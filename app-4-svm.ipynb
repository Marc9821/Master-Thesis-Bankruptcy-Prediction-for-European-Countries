{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master Thesis: Bankruptcy Prediction for European Countries\n",
    "Code written by Marc Zeugin (UZH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report, PrecisionRecallDisplay, confusion_matrix, RocCurveDisplay\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearnex.ensemble import RandomForestClassifier\n",
    "from sklearnex.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import IterativeImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.combine import SMOTEENN\n",
    "from skopt.space import Real, Integer\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.svm import LinearSVC\n",
    "from skopt import BayesSearchCV\n",
    "from joblib import dump, Memory\n",
    "from itertools import product\n",
    "from tempfile import mkdtemp\n",
    "from shutil import rmtree\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "import pyarrow\n",
    "import glob\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup key variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine training/testing ratio, default is 0.2\n",
    "tt_size = 0.2\n",
    "# number of splits for k-fold crossvalidation, default is 5\n",
    "k_splits = 5\n",
    "# set number of jobs to run in parallel, -1 means all processors, default is 1\n",
    "jobs = -1\n",
    "# number of iterations for BayesSearchCV\n",
    "n_iterations = 40\n",
    "# select scoring model to optimize, default is average_precision, the value used for the precision-recall curve\n",
    "scoring_metric = 'average_precision'\n",
    "# label for classification report\n",
    "label = ['Non-Bankrupt', 'Bankrupt']\n",
    "\n",
    "# absolute path to dataset\n",
    "path = 'C:/Users/marczeugin/Documents/Masterthesis/'\n",
    "# extension of dataset type\n",
    "ext = '*.csv'\n",
    "\n",
    "# determine the size (in inches) of the precision-recall curve figure, default is (4, 2)\n",
    "figure_size = (4, 2)\n",
    "# set dpi of small graphs, default is 100\n",
    "dpi_low = 100\n",
    "# set dpi of medium graphs, default is 200\n",
    "dpi_med = 200\n",
    "# set dpi of large graphs, default is 250\n",
    "dpi_high = 250\n",
    "\n",
    "# enable subsample of total dataset to be used for hyperparameter tuning, default is True\n",
    "allow_subsample = True\n",
    "# set subsample size of total dataset, default is .1 e.g. 10%\n",
    "subsample_size = 0.1\n",
    "# enable quick overview to run with subsample\n",
    "allow_subsample_overview = True\n",
    "# enable hyperparameter tuning with subsample\n",
    "allow_subsample_hyperparameter = True\n",
    "\n",
    "# allow to load dataset with SMOTEENN already run and imputation already imputed, default is True\n",
    "allow_computed_set = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create model lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list = ['complete', 'without years', 'without macro', 'without years and macro', 'complete SMOTEENN', 'without years SMOTEENN', 'without macro SMOTEENN', 'without years and macro SMOTEENN']\n",
    "\n",
    "X_list = np.load('X_list.npy', allow_pickle=True).tolist()\n",
    "X_list_m = np.load('X_list_m.npy', allow_pickle=True).tolist()\n",
    "y_list = np.load('y_list.npy', allow_pickle=True).tolist()\n",
    "y_list_m = np.load('y_list_m.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.7. Hyperparameter tuning for SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.7.1. Without SMOTEENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_list_svmc = dict()\n",
    "params_list_svmc['C'] = Real(1e-6, 1000.0, prior='log-uniform')\n",
    "params_list_svmc['penalty'] = ['l2', 'l1']\n",
    "params_list_svmc['loss'] = ['hinge', 'squared_hinge']\n",
    "model = LinearSVC(random_state=1, class_weight='balanced', dual=False, tol=1e-5)\n",
    "kfold = StratifiedKFold(n_splits=3, random_state=1, shuffle=True)\n",
    "grid = BayesSearchCV(estimator=model, search_spaces=params_list_svmc, scoring=scoring_metric, cv=kfold, error_score=0, random_state=1, n_iter=n_iterations, n_jobs=jobs)\n",
    "fig_cols = 2\n",
    "fig_rows = 4\n",
    "\n",
    "svmc_means_list = []\n",
    "svmc_names_list = []\n",
    "svmc_params_list = []\n",
    "svmc_max_mean_list = []\n",
    "svmc_best_result_list = []\n",
    "svmc_best_C = []\n",
    "svmc_best_penalty = []\n",
    "svmc_best_loss = []\n",
    "\n",
    "for i in range(0, int(len(X_list_m))):\n",
    "    start = time.perf_counter()\n",
    "    grid_result = grid.fit(X_list_m[i][0], y_list_m[i][0])\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    \n",
    "    svmc_names = []\n",
    "    for k in range(len(params)):\n",
    "        new_string = str(round(params[k]['C'],4)) + ' ' + params[k]['penalty'] + ' ' + params[k]['loss']\n",
    "        svmc_names.append(new_string)\n",
    "    \n",
    "    index_to_rm = []\n",
    "    for index, item in enumerate(params):\n",
    "        if item in params[:index]:\n",
    "            index_to_rm.append(index)\n",
    "    means = np.delete(means, index_to_rm)\n",
    "    svmc_names = np.delete(svmc_names, index_to_rm)\n",
    "    params = np.delete(params, index_to_rm)\n",
    "    max_mean = np.argmax(means)\n",
    "    \n",
    "    svmc_means_list.append(means)\n",
    "    svmc_names_list.append(svmc_names)\n",
    "    svmc_params_list.append(params)\n",
    "    svmc_max_mean_list.append(max_mean)\n",
    "    svmc_best_result_list.append(grid_result.best_score_)\n",
    "\n",
    "    print(f'Best {scoring_metric} of {round(grid_result.best_score_,4)} for {params[max_mean]}')\n",
    "\n",
    "    end = time.perf_counter()\n",
    "    print(f'Ran hyperparameter tuning in {end-start:0.4f} seconds')\n",
    "\n",
    "    svmc_best_C.append(grid_result.best_params_[\"C\"])\n",
    "    svmc_best_penalty.append(grid_result.best_params_[\"penalty\"])\n",
    "    svmc_best_loss.append(grid_result.best_params_[\"loss\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.7.2. With SMOTEENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cachedir = mkdtemp()\n",
    "memory = Memory(cachedir=cachedir, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_list_svmc_smoteenn = dict()\n",
    "params_list_svmc_smoteenn['model__C'] = Real(1e-6, 1000.0, prior='log-uniform')\n",
    "params_list_svmc_smoteenn['model__penalty'] = ['l1', 'l2']\n",
    "params_list_svmc_smoteenn['model__loss'] = ['hinge', 'squared_hinge']\n",
    "pipe = Pipeline([('SMOTEENN', SMOTEENN(smote=SMOTE(sampling_strategy='minority', random_state=1), enn=EditedNearestNeighbours(sampling_strategy='all'), \n",
    "                                       random_state=1, n_jobs=jobs)), ('scaler', StandardScaler()), ('model', LinearSVC(random_state=1, dual=False, tol=1e-5))], memory=memory)\n",
    "kfold = StratifiedKFold(n_splits=3, random_state=1, shuffle=True)\n",
    "grid = BayesSearchCV(estimator=pipe, search_spaces=params_list_svmc_smoteenn, scoring=scoring_metric, cv=kfold, error_score=0, random_state=1, n_iter=n_iterations, n_jobs=jobs)\n",
    "\n",
    "for i in range(0, int(len(X_list_m))):\n",
    "    start = time.perf_counter()\n",
    "    grid_result = grid.fit(X_list_m[i][0], y_list_m[i][0])\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    \n",
    "    svmc_names = []\n",
    "    for k in range(len(params)):\n",
    "        new_string = str(round(params[k]['model__C'],4)) + ' ' + params[k]['model__penalty'] + ' ' + params[k]['model__loss']\n",
    "        svmc_names.append(new_string)\n",
    "    \n",
    "    index_to_rm = []\n",
    "    for index, item in enumerate(means):\n",
    "        if item == 0.0:\n",
    "            index_to_rm.append(index)\n",
    "    means = np.delete(means, index_to_rm)\n",
    "    svmc_names = np.delete(svmc_names, index_to_rm)\n",
    "    params = np.delete(params, index_to_rm)\n",
    "\n",
    "    index_to_rm2 = []\n",
    "    for index, item in enumerate(params):\n",
    "        if item in params[:index]:\n",
    "            index_to_rm2.append(index)\n",
    "    means = np.delete(means, index_to_rm2)\n",
    "    svmc_names = np.delete(svmc_names, index_to_rm2)\n",
    "    params = np.delete(params, index_to_rm2)\n",
    "    max_mean = np.argmax(means)\n",
    "    \n",
    "    svmc_means_list.append(means)\n",
    "    svmc_names_list.append(svmc_names)\n",
    "    svmc_params_list.append(params)\n",
    "    svmc_max_mean_list.append(max_mean)\n",
    "    svmc_best_result_list.append(grid_result.best_score_)\n",
    "\n",
    "    print(f'Best {scoring_metric} of {round(grid_result.best_score_,4)} for {params[max_mean]}')\n",
    "\n",
    "    end = time.perf_counter()\n",
    "    print(f'Ran hyperparameter tuning in {end-start:0.4f} seconds')\n",
    "\n",
    "    svmc_best_C.append(grid_result.best_params_[\"model__C\"])\n",
    "    svmc_best_penalty.append(grid_result.best_params_[\"model__penalty\"])\n",
    "    svmc_best_loss.append(grid_result.best_params_[\"model__loss\"])\n",
    "    \n",
    "rmtree(cachedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = -1\n",
    "row = 0\n",
    "\n",
    "fig, ax = plt.subplots(int(len(svmc_means_list)/2), 2)\n",
    "fig.set_size_inches((30, 30))\n",
    "fig.tight_layout(h_pad=16, w_pad=2)\n",
    "fig.set_dpi(dpi_low)\n",
    "for i in range(0, int(len(svmc_means_list))):\n",
    "    if i % 2 == 0:\n",
    "        col += 1\n",
    "        row = 0\n",
    "    if i % 2 == 1:\n",
    "        row += 1\n",
    "        \n",
    "    ax[col, row].plot(range(len(svmc_names_list[i])), svmc_means_list[i], color='grey', marker='o', markerfacecolor='black')\n",
    "    ax[col, row].plot(svmc_max_mean_list[i], svmc_best_result_list[i], marker='o', markerfacecolor='red', markeredgecolor=\"red\")\n",
    "    ax[col, row].set_title(f'Mean {scoring_metric} for SVM with stratified {k_splits}-fold crossvalidation\\n{name_list[i]}')\n",
    "    ax[col, row].set_xticks(range(len(svmc_names_list[i])))\n",
    "    ax[col, row].set_xticklabels(svmc_names_list[i], rotation=45, ha='right')\n",
    "    ax[col, row].set_xlabel('SVM Hyperparameters (Kernel and C)')\n",
    "    ax[col, row].set_ylabel(scoring_metric)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.8. SVM with optimal hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmc_models = []\n",
    "svmc_accuracy = []\n",
    "svmc_precision = []\n",
    "svmc_recall = []\n",
    "svmc_f1 = []\n",
    "svmc_classification_report = []\n",
    "svmc_test_prediction = []\n",
    "\n",
    "for i, variant in enumerate(X_list):\n",
    "    start = time.perf_counter()\n",
    "    svmc = LinearSVC(penalty=svmc_best_penalty[i], loss=svmc_best_loss[i], C=svmc_best_C[i], random_state=1, class_weight='balanced', dual=False, tol=1e-5)\n",
    "    svmc.fit(variant[0], y_list[i][0])\n",
    "    svmc_test_pred = svmc.predict(variant[1])\n",
    "    svmc_test_prediction.append(svmc_test_pred)\n",
    "\n",
    "    svmc_accuracy.append(svmc.score(variant[1], y_list[i][1]))\n",
    "    svmc_precision.append(precision_score(y_list[i][1], svmc_test_pred))\n",
    "    svmc_recall.append(recall_score(y_list[i][1], svmc_test_pred))\n",
    "    svmc_f1.append(f1_score(y_list[i][1], svmc_test_pred))\n",
    "\n",
    "    svmc_classification_report.append(classification_report(y_list[i][1], svmc_test_pred, target_names=label))\n",
    "\n",
    "    end = time.perf_counter()\n",
    "    print(f'Ran model training and testing in {end-start:0.4f} seconds')\n",
    "\n",
    "    svmc_models.append(svmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmc_pr = []\n",
    "\n",
    "fig, ax = plt.subplots(int(len(svmc_means_list)/2), 2)\n",
    "fig.set_size_inches((20, 15))\n",
    "fig.tight_layout(pad=5.0)\n",
    "col = -1\n",
    "row = 0\n",
    "for i in range(0, int(len(svmc_means_list))):\n",
    "    if i % 2 == 0:\n",
    "        col += 1\n",
    "        row = 0\n",
    "    elif i % 2 == 1:\n",
    "        row += 1\n",
    "    \n",
    "    svmc_display = PrecisionRecallDisplay.from_estimator(svmc_models[i], X_list[i][1], y_list[i][1], name='SVM', color='black', ax=ax[col, row])\n",
    "    svmc_pr.append(svmc_display)\n",
    "    ax[col, row].set_title('SVM Precision-Recall curve '+name_list[i], fontweight='bold')\n",
    "    ax[col, row].legend(loc='best')\n",
    "    ax[col, row].set_xlabel('Recall')\n",
    "    ax[col, row].set_ylabel('Precision')\n",
    "    ax[col, row].set_xlim(-0.05, 1.05)\n",
    "    ax[col, row].set_xticks([0.0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "    ax[col, row].set_ylim(0, 1.05)\n",
    "    ax[col, row].set_yticks([0.00, 0.25, 0.50, 0.75, 1.00])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linestyle_list = ['solid', 'dashed', 'dotted', 'dashdot', 'solid', 'dashed', 'dotted', 'dashdot']\n",
    "color_list = ['black', 'black', 'black', 'black', 'grey', 'grey', 'grey', 'grey']\n",
    "\n",
    "ax = plt.gca()\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(8, 4)\n",
    "fig.set_dpi(dpi_high)\n",
    "for i in range(0, int(len(svmc_means_list))):\n",
    "    svmc_display = PrecisionRecallDisplay.from_estimator(svmc_models[i], X_list[i][1], y_list[i][1], name=f'SVM {name_list[i]}', \n",
    "                                                            color=color_list[i], linestyle=linestyle_list[i], ax=plt.gca())\n",
    "ax.set_title(\"SVM Combined Precision-Recall curve\")\n",
    "ax.legend(loc='best', prop={'size': 8})\n",
    "ax.set_xlabel('Recall')\n",
    "ax.set_ylabel('Precision')\n",
    "ax.set_xlim(-0.05, 1.05)\n",
    "ax.set_ylim(0, 1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(8, 4)\n",
    "fig.set_dpi(dpi_high)\n",
    "for i in range(0, 4):\n",
    "    svmc_display = PrecisionRecallDisplay.from_estimator(svmc_models[i], X_list[i][1], y_list[i][1], name=f'SVM {name_list[i]}', \n",
    "                                                            color=color_list[i], linestyle=linestyle_list[i], ax=plt.gca())\n",
    "ax.set_title(\"SVM Combined Precision-Recall curve\")\n",
    "ax.legend(loc='best', prop={'size': 8})\n",
    "ax.set_xlabel('Recall')\n",
    "ax.set_ylabel('Precision')\n",
    "ax.set_xlim(-0.05, 1.05)\n",
    "ax.set_ylim(0, 1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(8, 4)\n",
    "fig.set_dpi(dpi_high)\n",
    "for i in range(4, int(len(svmc_means_list))):\n",
    "    svmc_display = PrecisionRecallDisplay.from_estimator(svmc_models[i], X_list[i][1], y_list[i][1], name=f'SVM {name_list[i]}', \n",
    "                                                            color=color_list[i], linestyle=linestyle_list[i], ax=plt.gca())\n",
    "ax.set_title(\"SVM Combined Precision-Recall curve\")\n",
    "ax.legend(loc='best', prop={'size': 8})\n",
    "ax.set_xlabel('Recall')\n",
    "ax.set_ylabel('Precision')\n",
    "ax.set_xlim(-0.05, 1.05)\n",
    "ax.set_ylim(0, 1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(8, 4)\n",
    "fig.set_dpi(dpi_high)\n",
    "for i in range(0, int(len(svmc_means_list))):\n",
    "    svmc_display = RocCurveDisplay.from_estimator(svmc_models[i], X_list[i][1], y_list[i][1], name=f'SVM {name_list[i]}', \n",
    "                                                            color=color_list[i], linestyle=linestyle_list[i], ax=plt.gca())\n",
    "ax.set_title(\"SVM Combined AUROC\")\n",
    "ax.legend(loc='best', prop={'size': 8})\n",
    "ax.set_xlabel('Recall')\n",
    "ax.set_ylabel('Precision')\n",
    "ax.set_xlim(-0.05, 1.05)\n",
    "ax.set_ylim(0, 1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(8, 4)\n",
    "fig.set_dpi(dpi_high)\n",
    "for i in range(0, 4):\n",
    "    svmc_display = RocCurveDisplay.from_estimator(svmc_models[i], X_list[i][1], y_list[i][1], name=f'SVM {name_list[i]}', \n",
    "                                                            color=color_list[i], linestyle=linestyle_list[i], ax=plt.gca())\n",
    "ax.set_title(\"SVM Combined AUROC\")\n",
    "ax.legend(loc='best', prop={'size': 8})\n",
    "ax.set_xlabel('Recall')\n",
    "ax.set_ylabel('Precision')\n",
    "ax.set_xlim(-0.05, 1.05)\n",
    "ax.set_ylim(0, 1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(8, 4)\n",
    "fig.set_dpi(dpi_high)\n",
    "for i in range(4, int(len(svmc_means_list))):\n",
    "    svmc_display = RocCurveDisplay.from_estimator(svmc_models[i], X_list[i][1], y_list[i][1], name=f'SVM {name_list[i]}', \n",
    "                                                            color=color_list[i], linestyle=linestyle_list[i], ax=plt.gca())\n",
    "ax.set_title(\"SVM Combined AUROC\")\n",
    "ax.legend(loc='best', prop={'size': 8})\n",
    "ax.set_xlabel('Recall')\n",
    "ax.set_ylabel('Precision')\n",
    "ax.set_xlim(-0.05, 1.05)\n",
    "ax.set_ylim(0, 1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot confusion matrix for each classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_list = []\n",
    "heat_map_list = []\n",
    "\n",
    "temp_conf_mat = []\n",
    "temp_heat_map = []\n",
    "for i in range(0, int(len(svmc_means_list))):\n",
    "    conf_mat = confusion_matrix(y_list[i][1], svmc_test_prediction[i])\n",
    "    temp_conf_mat.append(conf_mat)\n",
    "    heat = pd.DataFrame(conf_mat, columns=np.unique(y_list[i][1]), index=np.unique(y_list[i][1]))\n",
    "    heat.index.name = 'Actual'\n",
    "    heat.columns.name = 'Predicted'\n",
    "    temp_heat_map.append(heat)\n",
    "\n",
    "confusion_matrix_list.append(temp_conf_mat)\n",
    "heat_map_list.append(temp_heat_map)\n",
    "\n",
    "fig, ax = plt.subplots(int(len(svmc_means_list)/4), 4, figsize=(20, 18))\n",
    "fig.subplots_adjust(left=None, bottom=None, right=2, top=None, wspace=None, hspace=0.3)\n",
    "\n",
    "sns.set(font_scale=1.4)\n",
    "lc = 'Grey'\n",
    "lw = 1\n",
    "col = -1\n",
    "row = 0\n",
    "for i in range(int(len(svmc_means_list))):\n",
    "    if i % 4 == 0:\n",
    "        col += 1\n",
    "        row = 0\n",
    "    else:\n",
    "        row += 1\n",
    "    \n",
    "    sns.heatmap(heat_map_list[-1][i], cmap='Greys', annot=True, annot_kws={'size': 16}, fmt='g', ax=ax[col, row], xticklabels=label, yticklabels=label, linecolor=lc, linewidths=lw)\n",
    "    ax[col, row].set_title(('SVM '+name_list[i]), fontweight='bold')\n",
    "sns.set(font_scale=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rc_file_defaults()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save output for model persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Model 1': [], 'Model 2': [], 'Model 3': [], 'Model 4': [], 'Model 5': [], 'Model 6': [], 'Model 7': [], 'Model 8': []}\n",
    "for i, model in enumerate(data):\n",
    "    data[model].append(svmc_means_list[i])\n",
    "    data[model].append(svmc_params_list[i])\n",
    "    data[model].append(svmc_best_result_list[i])\n",
    "    data[model].append(svmc_best_C[i])\n",
    "    data[model].append(svmc_best_penalty[i])\n",
    "    data[model].append(svmc_best_loss[i])\n",
    "    dump(svmc_models[i], f'models/output-svmc{i}.joblib')\n",
    "    data[model].append(svmc_accuracy[i])\n",
    "    data[model].append(svmc_precision[i])\n",
    "    data[model].append(svmc_recall[i])\n",
    "    data[model].append(svmc_f1[i])\n",
    "    data[model].append(svmc_classification_report[i])\n",
    "    data[model].append(svmc_test_prediction[i])\n",
    "    data[model].append(svmc_pr[i])\n",
    "    data[model].append(heat_map_list[0][i])\n",
    "    \n",
    "output_df = pd.DataFrame(data)\n",
    "index_list = ['svmc_means_list','svmc_params_list','svmc_best_result_list','svmc_best_C','svmc_best_penalty','svmc_best_loss','svmc_accuracy','svmc_precision','svmc_recall','svmc_f1','svmc_classification_report',\n",
    "                'svmc_test_prediction','svmc_pr','heat_map_svmc']\n",
    "output_df.insert(0, 'Name', index_list)\n",
    "output_df.set_index(output_df['Name'], inplace=True)\n",
    "output_df.drop('Name', axis=1, inplace=True)\n",
    "dump(output_df, 'models/output-svmc.joblib')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aef203514c858290544fd6a14248b5f64855080360fc299c24eb5474b48fd873"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
