{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master Thesis: Bankruptcy Prediction for European Countries\n",
    "Code written by Marc Zeugin (UZH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report, PrecisionRecallDisplay, confusion_matrix, RocCurveDisplay\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearnex.ensemble import RandomForestClassifier\n",
    "from sklearnex.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import IterativeImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.combine import SMOTEENN\n",
    "from skopt.space import Real, Integer\n",
    "from joblib import dump, Memory, load\n",
    "from matplotlib import pyplot as plt\n",
    "from skopt import BayesSearchCV\n",
    "from sklearnex.svm import SVC\n",
    "from itertools import product\n",
    "from tempfile import mkdtemp\n",
    "from shutil import rmtree\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "import pyarrow\n",
    "import glob\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup key variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine training/testing ratio, default is 0.2\n",
    "tt_size = 0.2\n",
    "# number of splits for k-fold crossvalidation, default is 5\n",
    "k_splits = 5\n",
    "# set number of jobs to run in parallel, -1 means all processors, default is 1\n",
    "jobs = -1\n",
    "# number of iterations for BayesSearchCV\n",
    "n_iterations = 40\n",
    "# select scoring model to optimize, default is average_precision, the value used for the precision-recall curve\n",
    "scoring_metric = 'average_precision'\n",
    "# label for classification report\n",
    "label = ['Non-Bankrupt', 'Bankrupt']\n",
    "\n",
    "# absolute path to dataset\n",
    "path = 'C:/Users/marczeugin/Documents/Masterthesis/datasets/'\n",
    "# extension of dataset type\n",
    "ext = '*.csv'\n",
    "\n",
    "# determine the size (in inches) of the precision-recall curve figure, default is (4, 2)\n",
    "figure_size = (4, 2)\n",
    "# set dpi of small graphs, default is 100\n",
    "dpi_low = 100\n",
    "# set dpi of medium graphs, default is 200\n",
    "dpi_med = 200\n",
    "# set dpi of large graphs, default is 250\n",
    "dpi_high = 250\n",
    "\n",
    "# enable subsample of total dataset to be used for hyperparameter tuning, default is True\n",
    "allow_subsample = True\n",
    "# set subsample size of total dataset, default is .1 e.g. 10%\n",
    "subsample_size = 0.1\n",
    "# enable quick overview to run with subsample\n",
    "allow_subsample_overview = True\n",
    "# enable hyperparameter tuning with subsample\n",
    "allow_subsample_hyperparameter = True\n",
    "\n",
    "# allow to load dataset with SMOTEENN already run and imputation already imputed, default is True\n",
    "allow_computed_set = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create model lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list = ['complete', 'without years', 'without macro', 'without years and macro', 'complete SMOTEENN', 'without years SMOTEENN', 'without macro SMOTEENN', 'without years and macro SMOTEENN']\n",
    "\n",
    "X_list = np.load('X_list.npy', allow_pickle=True).tolist()\n",
    "X_list_m = np.load('X_list_m.npy', allow_pickle=True).tolist()\n",
    "y_list = np.load('y_list.npy', allow_pickle=True).tolist()\n",
    "y_list_m = np.load('y_list_m.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5. Hyperparameter tuning for random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.5.1. Without SMOTEENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_list_rf = dict()\n",
    "params_list_rf['n_estimators'] = Integer(10, 650)\n",
    "params_list_rf['max_depth'] = Integer(1, 16)\n",
    "params_list_rf['max_features'] = ['auto', 'log2']\n",
    "model = RandomForestClassifier(random_state=1, n_jobs=jobs, class_weight='balanced')\n",
    "kfold = StratifiedKFold(n_splits=k_splits, random_state=1, shuffle=True)\n",
    "grid = BayesSearchCV(estimator=model, search_spaces=params_list_rf, scoring=scoring_metric, cv=kfold, error_score=0, random_state=1, n_jobs=jobs, n_iter=n_iterations)\n",
    "fig_cols = 2\n",
    "fig_rows = 4\n",
    "\n",
    "rfc_means_list = []\n",
    "rfc_names_list = []\n",
    "rfc_params_list = []\n",
    "rfc_best_result_list = []\n",
    "rfc_max_means_list = []\n",
    "rfc_max_depth = []\n",
    "rfc_n_estimator = []\n",
    "rfc_max_features = []\n",
    "\n",
    "for i in range(0, 3):\n",
    "    start = time.perf_counter()\n",
    "    grid_result = grid.fit(X_list_m[i][0], y_list_m[i][0])\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    \n",
    "    rfc_names = []\n",
    "    for k in range(len(params)):\n",
    "        new_string = str(params[k]['max_depth']) + ' ' + params[k]['max_features'] + ' ' + str(params[k]['n_estimators'])\n",
    "        rfc_names.append(new_string)\n",
    "    \n",
    "    index_to_rm = []\n",
    "    for index, item in enumerate(params):\n",
    "        if item in params[:index]:\n",
    "            index_to_rm.append(index)\n",
    "    means = np.delete(means, index_to_rm)\n",
    "    rfc_names = np.delete(rfc_names, index_to_rm)\n",
    "    params = np.delete(params, index_to_rm)\n",
    "    max_mean = np.argmax(means)\n",
    "    \n",
    "    rfc_means_list.append(means)\n",
    "    rfc_names_list.append(rfc_names)\n",
    "    rfc_params_list.append(params)\n",
    "    rfc_max_means_list.append(max_mean)\n",
    "    rfc_best_result_list.append(grid_result.best_score_)\n",
    "    \n",
    "    print(f'Best {scoring_metric} of {round(grid_result.best_score_,4)} for max depth of {grid_result.best_params_[\"max_depth\"]}, number of estimators of {grid_result.best_params_[\"n_estimators\"]}, and max features {grid_result.best_params_[\"max_features\"]}')\n",
    "    \n",
    "    end = time.perf_counter()\n",
    "    print(f'Ran hyperparameter tuning in {end-start:0.4f} seconds')\n",
    "\n",
    "    rfc_max_depth.append(grid_result.best_params_[\"max_depth\"])\n",
    "    rfc_n_estimator.append(grid_result.best_params_[\"n_estimators\"])\n",
    "    rfc_max_features.append(grid_result.best_params_[\"max_features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_list_rf = dict()\n",
    "params_list_rf['n_estimators'] = Integer(10, 650)\n",
    "params_list_rf['max_depth'] = Integer(1, 16)\n",
    "params_list_rf['max_features'] = ['auto', 'log2']\n",
    "model = RandomForestClassifier(random_state=1, n_jobs=jobs, class_weight='balanced')\n",
    "kfold = StratifiedKFold(n_splits=k_splits, random_state=1, shuffle=True)\n",
    "grid = BayesSearchCV(estimator=model, search_spaces=params_list_rf, scoring=scoring_metric, cv=kfold, error_score=0, random_state=1, n_jobs=4, n_iter=n_iterations)\n",
    "fig_cols = 2\n",
    "fig_rows = 4\n",
    "\n",
    "for i in range(3, int(len(X_list_m))):\n",
    "    start = time.perf_counter()\n",
    "    grid_result = grid.fit(X_list_m[i][0], y_list_m[i][0])\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    \n",
    "    rfc_names = []\n",
    "    for k in range(len(params)):\n",
    "        new_string = str(params[k]['max_depth']) + ' ' + params[k]['max_features'] + ' ' + str(params[k]['n_estimators'])\n",
    "        rfc_names.append(new_string)\n",
    "    \n",
    "    index_to_rm = []\n",
    "    for index, item in enumerate(params):\n",
    "        if item in params[:index]:\n",
    "            index_to_rm.append(index)\n",
    "    means = np.delete(means, index_to_rm)\n",
    "    rfc_names = np.delete(rfc_names, index_to_rm)\n",
    "    params = np.delete(params, index_to_rm)\n",
    "    max_mean = np.argmax(means)\n",
    "    \n",
    "    rfc_means_list.append(means)\n",
    "    rfc_names_list.append(rfc_names)\n",
    "    rfc_params_list.append(params)\n",
    "    rfc_max_means_list.append(max_mean)\n",
    "    rfc_best_result_list.append(grid_result.best_score_)\n",
    "    \n",
    "    print(f'Best {scoring_metric} of {round(grid_result.best_score_,4)} for max depth of {grid_result.best_params_[\"max_depth\"]}, number of estimators of {grid_result.best_params_[\"n_estimators\"]}, and max features {grid_result.best_params_[\"max_features\"]}')\n",
    "    \n",
    "    end = time.perf_counter()\n",
    "    print(f'Ran hyperparameter tuning in {end-start:0.4f} seconds')\n",
    "\n",
    "    rfc_max_depth.append(grid_result.best_params_[\"max_depth\"])\n",
    "    rfc_n_estimator.append(grid_result.best_params_[\"n_estimators\"])\n",
    "    rfc_max_features.append(grid_result.best_params_[\"max_features\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.5.2. With SMOTEENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cachedir = mkdtemp()\n",
    "memory = Memory(cachedir=cachedir, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_list_rf_smoteenn = dict()\n",
    "params_list_rf_smoteenn['model__n_estimators'] = Integer(10, 650)\n",
    "params_list_rf_smoteenn['model__max_depth'] = Integer(1, 16)\n",
    "params_list_rf_smoteenn['model__max_features'] = ['auto', 'log2']\n",
    "pipe = Pipeline([('SMOTEENN', SMOTEENN(smote=SMOTE(sampling_strategy='minority', random_state=1), enn=EditedNearestNeighbours(sampling_strategy='all'), \n",
    "                                       random_state=1, n_jobs=jobs)), ('scaler', StandardScaler()), ('model', RandomForestClassifier(random_state=1, n_jobs=jobs))], memory=memory)\n",
    "kfold = StratifiedKFold(n_splits=k_splits, random_state=1, shuffle=True)\n",
    "grid = BayesSearchCV(estimator=pipe, search_spaces=params_list_rf_smoteenn, scoring=scoring_metric, cv=kfold, error_score=0, random_state=1, n_jobs=jobs, n_iter=n_iterations)\n",
    "fig_cols = 2\n",
    "fig_rows = 4\n",
    "\n",
    "for i in range(0, 1):\n",
    "    start = time.perf_counter()\n",
    "    if i == 3:\n",
    "        grid = BayesSearchCV(estimator=pipe, search_spaces=params_list_rf_smoteenn, scoring=scoring_metric, cv=kfold, error_score=0, random_state=1, n_jobs=4, n_iter=n_iterations)\n",
    "    grid_result = grid.fit(X_list_m[i][0], y_list_m[i][0])\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    \n",
    "    rfc_names = []\n",
    "    for k in range(len(params)):\n",
    "        new_string = str(params[k]['model__max_depth']) + ' ' + params[k]['model__max_features'] + ' ' + str(params[k]['model__n_estimators'])\n",
    "        rfc_names.append(new_string)\n",
    "    \n",
    "    index_to_rm = []\n",
    "    for index, item in enumerate(params):\n",
    "        if item in params[:index]:\n",
    "            index_to_rm.append(index)\n",
    "    means = np.delete(means, index_to_rm)\n",
    "    rfc_names = np.delete(rfc_names, index_to_rm)\n",
    "    params = np.delete(params, index_to_rm)\n",
    "    max_mean = np.argmax(means)\n",
    "    \n",
    "    rfc_means_list.append(means)\n",
    "    rfc_names_list.append(rfc_names)\n",
    "    rfc_params_list.append(params)\n",
    "    rfc_max_means_list.append(max_mean)\n",
    "    rfc_best_result_list.append(grid_result.best_score_)\n",
    "    \n",
    "    print(f'Best {scoring_metric} of {round(grid_result.best_score_,4)} for max depth of {grid_result.best_params_[\"model__max_depth\"]}, number of estimators of {grid_result.best_params_[\"model__n_estimators\"]}, and max features {grid_result.best_params_[\"model__max_features\"]}')\n",
    "    \n",
    "    end = time.perf_counter()\n",
    "    print(f'Ran hyperparameter tuning in {end-start:0.4f} seconds')\n",
    "\n",
    "    rfc_max_depth.append(grid_result.best_params_[\"model__max_depth\"])\n",
    "    rfc_n_estimator.append(grid_result.best_params_[\"model__n_estimators\"])\n",
    "    rfc_max_features.append(grid_result.best_params_[\"model__max_features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_list_rf_smoteenn = dict()\n",
    "params_list_rf_smoteenn['model__n_estimators'] = Integer(10, 650)\n",
    "params_list_rf_smoteenn['model__max_depth'] = Integer(1, 16)\n",
    "params_list_rf_smoteenn['model__max_features'] = ['auto', 'log2']\n",
    "pipe = Pipeline([('SMOTEENN', SMOTEENN(smote=SMOTE(sampling_strategy='minority', random_state=1), enn=EditedNearestNeighbours(sampling_strategy='all'), \n",
    "                                       random_state=1, n_jobs=jobs)), ('model', RandomForestClassifier(random_state=1, n_jobs=jobs))], memory=memory)\n",
    "kfold = StratifiedKFold(n_splits=k_splits, random_state=1, shuffle=True)\n",
    "grid = BayesSearchCV(estimator=pipe, search_spaces=params_list_rf_smoteenn, scoring=scoring_metric, cv=kfold, error_score=0, random_state=1, n_jobs=jobs, n_iter=n_iterations)\n",
    "fig_cols = 2\n",
    "fig_rows = 4\n",
    "\n",
    "for i in range(1, 2):\n",
    "    start = time.perf_counter()\n",
    "    if i == 3:\n",
    "        grid = BayesSearchCV(estimator=pipe, search_spaces=params_list_rf_smoteenn, scoring=scoring_metric, cv=kfold, error_score=0, random_state=1, n_jobs=4, n_iter=n_iterations)\n",
    "    grid_result = grid.fit(X_list_m[i][0], y_list_m[i][0])\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    \n",
    "    rfc_names = []\n",
    "    for k in range(len(params)):\n",
    "        new_string = str(params[k]['model__max_depth']) + ' ' + params[k]['model__max_features'] + ' ' + str(params[k]['model__n_estimators'])\n",
    "        rfc_names.append(new_string)\n",
    "    \n",
    "    index_to_rm = []\n",
    "    for index, item in enumerate(params):\n",
    "        if item in params[:index]:\n",
    "            index_to_rm.append(index)\n",
    "    means = np.delete(means, index_to_rm)\n",
    "    rfc_names = np.delete(rfc_names, index_to_rm)\n",
    "    params = np.delete(params, index_to_rm)\n",
    "    max_mean = np.argmax(means)\n",
    "    \n",
    "    rfc_means_list.append(means)\n",
    "    rfc_names_list.append(rfc_names)\n",
    "    rfc_params_list.append(params)\n",
    "    rfc_max_means_list.append(max_mean)\n",
    "    rfc_best_result_list.append(grid_result.best_score_)\n",
    "    \n",
    "    print(f'Best {scoring_metric} of {round(grid_result.best_score_,4)} for max depth of {grid_result.best_params_[\"model__max_depth\"]}, number of estimators of {grid_result.best_params_[\"model__n_estimators\"]}, and max features {grid_result.best_params_[\"model__max_features\"]}')\n",
    "    \n",
    "    end = time.perf_counter()\n",
    "    print(f'Ran hyperparameter tuning in {end-start:0.4f} seconds')\n",
    "\n",
    "    rfc_max_depth.append(grid_result.best_params_[\"model__max_depth\"])\n",
    "    rfc_n_estimator.append(grid_result.best_params_[\"model__n_estimators\"])\n",
    "    rfc_max_features.append(grid_result.best_params_[\"model__max_features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_list_rf_smoteenn = dict()\n",
    "params_list_rf_smoteenn['model__n_estimators'] = Integer(10, 650)\n",
    "params_list_rf_smoteenn['model__max_depth'] = Integer(1, 16)\n",
    "params_list_rf_smoteenn['model__max_features'] = ['auto', 'log2']\n",
    "pipe = Pipeline([('SMOTEENN', SMOTEENN(smote=SMOTE(sampling_strategy='minority', random_state=1), enn=EditedNearestNeighbours(sampling_strategy='all'), \n",
    "                                       random_state=1, n_jobs=jobs)), ('model', RandomForestClassifier(random_state=1, n_jobs=jobs))], memory=memory)\n",
    "kfold = StratifiedKFold(n_splits=k_splits, random_state=1, shuffle=True)\n",
    "grid = BayesSearchCV(estimator=pipe, search_spaces=params_list_rf_smoteenn, scoring=scoring_metric, cv=kfold, error_score=0, random_state=1, n_jobs=4, n_iter=n_iterations)\n",
    "fig_cols = 2\n",
    "fig_rows = 4\n",
    "\n",
    "for i in range(2, 3):\n",
    "    start = time.perf_counter()\n",
    "    if i == 3:\n",
    "        grid = BayesSearchCV(estimator=pipe, search_spaces=params_list_rf_smoteenn, scoring=scoring_metric, cv=kfold, error_score=0, random_state=1, n_jobs=4, n_iter=n_iterations)\n",
    "    grid_result = grid.fit(X_list_m[i][0], y_list_m[i][0])\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    \n",
    "    rfc_names = []\n",
    "    for k in range(len(params)):\n",
    "        new_string = str(params[k]['model__max_depth']) + ' ' + params[k]['model__max_features'] + ' ' + str(params[k]['model__n_estimators'])\n",
    "        rfc_names.append(new_string)\n",
    "    \n",
    "    index_to_rm = []\n",
    "    for index, item in enumerate(params):\n",
    "        if item in params[:index]:\n",
    "            index_to_rm.append(index)\n",
    "    means = np.delete(means, index_to_rm)\n",
    "    rfc_names = np.delete(rfc_names, index_to_rm)\n",
    "    params = np.delete(params, index_to_rm)\n",
    "    max_mean = np.argmax(means)\n",
    "    \n",
    "    rfc_means_list.append(means)\n",
    "    rfc_names_list.append(rfc_names)\n",
    "    rfc_params_list.append(params)\n",
    "    rfc_max_means_list.append(max_mean)\n",
    "    rfc_best_result_list.append(grid_result.best_score_)\n",
    "    \n",
    "    print(f'Best {scoring_metric} of {round(grid_result.best_score_,4)} for max depth of {grid_result.best_params_[\"model__max_depth\"]}, number of estimators of {grid_result.best_params_[\"model__n_estimators\"]}, and max features {grid_result.best_params_[\"model__max_features\"]}')\n",
    "    \n",
    "    end = time.perf_counter()\n",
    "    print(f'Ran hyperparameter tuning in {end-start:0.4f} seconds')\n",
    "\n",
    "    rfc_max_depth.append(grid_result.best_params_[\"model__max_depth\"])\n",
    "    rfc_n_estimator.append(grid_result.best_params_[\"model__n_estimators\"])\n",
    "    rfc_max_features.append(grid_result.best_params_[\"model__max_features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_list_rf_smoteenn = dict()\n",
    "params_list_rf_smoteenn['model__n_estimators'] = Integer(10, 650)\n",
    "params_list_rf_smoteenn['model__max_depth'] = Integer(1, 16)\n",
    "params_list_rf_smoteenn['model__max_features'] = ['auto', 'log2']\n",
    "pipe = Pipeline([('SMOTEENN', SMOTEENN(smote=SMOTE(sampling_strategy='minority', random_state=1), enn=EditedNearestNeighbours(sampling_strategy='all'), \n",
    "                                       random_state=1, n_jobs=jobs)), ('model', RandomForestClassifier(random_state=1, n_jobs=jobs))], memory=memory)\n",
    "kfold = StratifiedKFold(n_splits=k_splits, random_state=1, shuffle=True)\n",
    "grid = BayesSearchCV(estimator=pipe, search_spaces=params_list_rf_smoteenn, scoring=scoring_metric, cv=kfold, error_score=0, random_state=1, n_jobs=3, n_iter=n_iterations)\n",
    "fig_cols = 2\n",
    "fig_rows = 4\n",
    "\n",
    "for i in range(3, 4):\n",
    "    start = time.perf_counter()\n",
    "    grid_result = grid.fit(X_list_m[i][0], y_list_m[i][0])\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    \n",
    "    rfc_names = []\n",
    "    for k in range(len(params)):\n",
    "        new_string = str(params[k]['model__max_depth']) + ' ' + params[k]['model__max_features'] + ' ' + str(params[k]['model__n_estimators'])\n",
    "        rfc_names.append(new_string)\n",
    "    \n",
    "    index_to_rm = []\n",
    "    for index, item in enumerate(params):\n",
    "        if item in params[:index]:\n",
    "            index_to_rm.append(index)\n",
    "    means = np.delete(means, index_to_rm)\n",
    "    rfc_names = np.delete(rfc_names, index_to_rm)\n",
    "    params = np.delete(params, index_to_rm)\n",
    "    max_mean = np.argmax(means)\n",
    "    \n",
    "    rfc_means_list.append(means)\n",
    "    rfc_names_list.append(rfc_names)\n",
    "    rfc_params_list.append(params)\n",
    "    rfc_max_means_list.append(max_mean)\n",
    "    rfc_best_result_list.append(grid_result.best_score_)\n",
    "    \n",
    "    print(f'Best {scoring_metric} of {round(grid_result.best_score_,4)} for max depth of {grid_result.best_params_[\"model__max_depth\"]}, number of estimators of {grid_result.best_params_[\"model__n_estimators\"]}, and max features {grid_result.best_params_[\"model__max_features\"]}')\n",
    "    \n",
    "    end = time.perf_counter()\n",
    "    print(f'Ran hyperparameter tuning in {end-start:0.4f} seconds')\n",
    "\n",
    "    rfc_max_depth.append(grid_result.best_params_[\"model__max_depth\"])\n",
    "    rfc_n_estimator.append(grid_result.best_params_[\"model__n_estimators\"])\n",
    "    rfc_max_features.append(grid_result.best_params_[\"model__max_features\"])\n",
    "\n",
    "rmtree(cachedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = -1\n",
    "row = 0\n",
    "\n",
    "fig, ax = plt.subplots(int(len(rfc_means_list)/2), 2)\n",
    "fig.set_size_inches((30, 30))\n",
    "fig.tight_layout(h_pad=25.0, w_pad=4)\n",
    "fig.set_dpi(dpi_low)\n",
    "for i in range(0, int(len(rfc_means_list))):\n",
    "    if i % 2 == 0:\n",
    "        col += 1\n",
    "        row = 0\n",
    "    if i % 2 == 1:\n",
    "        row += 1\n",
    "        \n",
    "    ax[col, row].plot(range(len(rfc_names_list[i])), rfc_means_list[i], color='grey', marker='o', markerfacecolor='black')\n",
    "    ax[col, row].plot(rfc_max_means_list[i], rfc_best_result_list[i], marker='o', markerfacecolor='red', markeredgecolor=\"red\")\n",
    "    ax[col, row].set_title(f'Mean {scoring_metric} for Random Forest with stratified {k_splits}-fold crossvalidation\\n{name_list[i]}')\n",
    "    ax[col, row].set_xticks(range(len(rfc_names_list[i])))\n",
    "    ax[col, row].set_xticklabels(rfc_names_list[i], rotation=45, ha='right')\n",
    "    ax[col, row].set_xlabel('Random Forest Hyperparameters (Max depth, max features and n estimators)')\n",
    "    ax[col, row].set_ylabel(scoring_metric)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Model 1': [], 'Model 2': [], 'Model 3': [], 'Model 4': [], 'Model 5': [], 'Model 6': [], 'Model 7': [], 'Model 8': []}\n",
    "for i, model in enumerate(data):\n",
    "    data[model].append(rfc_means_list[i])\n",
    "    data[model].append(rfc_params_list[i])\n",
    "    data[model].append(rfc_best_result_list[i])\n",
    "    data[model].append(rfc_max_depth[i])\n",
    "    data[model].append(rfc_n_estimator[i])\n",
    "    \n",
    "output_df = pd.DataFrame(data)\n",
    "index_list = ['rfc_means_list','rfc_params_list','rfc_best_result_list','rfc_max_depth','rfc_n_estimator']\n",
    "output_df.insert(0, 'Name', index_list)\n",
    "output_df.set_index(output_df['Name'], inplace=True)\n",
    "output_df.drop('Name', axis=1, inplace=True)\n",
    "dump(output_df, 'models/output-rfc.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6. Random forest with optimal hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_models = []\n",
    "rfc_accuracy = []\n",
    "rfc_precision = []\n",
    "rfc_recall = []\n",
    "rfc_f1 = []\n",
    "rfc_classification_report = []\n",
    "rfc_test_prediction = []\n",
    "\n",
    "for i, variant in enumerate(X_list):\n",
    "    if i > 3:\n",
    "        continue\n",
    "    else:\n",
    "        print(i)\n",
    "        rfc = RandomForestClassifier(max_depth=rfc_max_depth[i], n_estimators=rfc_n_estimator[i], max_features=rfc_max_features[i], n_jobs=jobs, random_state=1, class_weight='balanced')\n",
    "        rfc.fit(variant[0], y_list[i][0])\n",
    "        rfc_test_pred = rfc.predict(variant[1])\n",
    "        rfc_test_prediction.append(rfc_test_pred)\n",
    "\n",
    "        rfc_accuracy.append(rfc.score(variant[1], y_list[i][1]))\n",
    "        rfc_precision.append(precision_score(y_list[i][1], rfc_test_pred))\n",
    "        rfc_recall.append(recall_score(y_list[i][1], rfc_test_pred))\n",
    "        rfc_f1.append(f1_score(y_list[i][1], rfc_test_pred))\n",
    "\n",
    "        rfc_classification_report.append(classification_report(y_list[i][1], rfc_test_pred, target_names=label))\n",
    "\n",
    "        rfc_models.append(rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, variant in enumerate(X_list):\n",
    "    if i <= 3:\n",
    "        continue\n",
    "    else:\n",
    "        print(i)\n",
    "        rfc = RandomForestClassifier(max_depth=rfc_max_depth[i], n_estimators=rfc_n_estimator[i], max_features=rfc_max_features[i], n_jobs=jobs, random_state=1, class_weight='balanced')\n",
    "        rfc.fit(variant[0], y_list[i][0])\n",
    "        rfc_test_pred = rfc.predict(variant[1])\n",
    "        rfc_test_prediction.append(rfc_test_pred)\n",
    "\n",
    "        rfc_accuracy.append(rfc.score(variant[1], y_list[i][1]))\n",
    "        rfc_precision.append(precision_score(y_list[i][1], rfc_test_pred))\n",
    "        rfc_recall.append(recall_score(y_list[i][1], rfc_test_pred))\n",
    "        rfc_f1.append(f1_score(y_list[i][1], rfc_test_pred))\n",
    "\n",
    "        rfc_classification_report.append(classification_report(y_list[i][1], rfc_test_pred, target_names=label))\n",
    "\n",
    "        rfc_models.append(rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_pr = []\n",
    "\n",
    "fig, ax = plt.subplots(int(len(rfc_means_list)/2), 2)\n",
    "fig.set_size_inches((20, 15))\n",
    "fig.tight_layout(pad=5.0)\n",
    "col = -1\n",
    "row = 0\n",
    "for i in range(0, int(len(rfc_means_list))):\n",
    "    if i % 2 == 0:\n",
    "        col += 1\n",
    "        row = 0\n",
    "    elif i % 2 == 1:\n",
    "        row += 1\n",
    "    \n",
    "    rfc_display = PrecisionRecallDisplay.from_estimator(rfc_models[i], X_list[i][1], y_list[i][1], name='Random Forest', color='black', ax=ax[col, row])\n",
    "    rfc_pr.append(rfc_display)\n",
    "    ax[col, row].set_title('Random Forest Precision-Recall curve '+name_list[i], fontweight='bold')\n",
    "    ax[col, row].legend(loc='best')\n",
    "    ax[col, row].set_xlabel('Recall')\n",
    "    ax[col, row].set_ylabel('Precision')\n",
    "    ax[col, row].set_xlim(-0.05, 1.05)\n",
    "    ax[col, row].set_xticks([0.0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "    ax[col, row].set_ylim(0, 1.05)\n",
    "    ax[col, row].set_yticks([0.00, 0.25, 0.50, 0.75, 1.00])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linestyle_list = ['solid', 'dashed', 'dotted', 'dashdot', 'solid', 'dashed', 'dotted', 'dashdot']\n",
    "color_list = ['black', 'black', 'black', 'black', 'grey', 'grey', 'grey', 'grey']\n",
    "\n",
    "ax = plt.gca()\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(8, 4)\n",
    "fig.set_dpi(dpi_high)\n",
    "for i in range(0, int(len(rfc_means_list))):\n",
    "    neigh_display = PrecisionRecallDisplay.from_estimator(rfc_models[i], X_list[i][1], y_list[i][1], name=f'Random forest {name_list[i]}', \n",
    "                                                            color=color_list[i], linestyle=linestyle_list[i], ax=plt.gca())\n",
    "ax.set_title(\"Random Forest Combined Precision-Recall curve\")\n",
    "ax.legend(loc='best', prop={'size': 8})\n",
    "ax.set_xlabel('Recall')\n",
    "ax.set_ylabel('Precision')\n",
    "ax.set_xlim(-0.05, 1.05)\n",
    "ax.set_ylim(0, 1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(8, 4)\n",
    "fig.set_dpi(dpi_high)\n",
    "for i in range(0, 4):\n",
    "    neigh_display = PrecisionRecallDisplay.from_estimator(rfc_models[i], X_list[i][1], y_list[i][1], name=f'Random forest {name_list[i]}', \n",
    "                                                            color=color_list[i], linestyle=linestyle_list[i], ax=plt.gca())\n",
    "ax.set_title(\"Random Forest Combined Precision-Recall curve\")\n",
    "ax.legend(loc='best', prop={'size': 8})\n",
    "ax.set_xlabel('Recall')\n",
    "ax.set_ylabel('Precision')\n",
    "ax.set_xlim(-0.05, 1.05)\n",
    "ax.set_ylim(0, 1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(8, 4)\n",
    "fig.set_dpi(dpi_high)\n",
    "for i in range(4, 8):\n",
    "    neigh_display = PrecisionRecallDisplay.from_estimator(rfc_models[i], X_list[i][1], y_list[i][1], name=f'Random forest {name_list[i]}', \n",
    "                                                            color=color_list[i], linestyle=linestyle_list[i], ax=plt.gca())\n",
    "ax.set_title(\"Random Forest Combined Precision-Recall curve\")\n",
    "ax.legend(loc='best', prop={'size': 8})\n",
    "ax.set_xlabel('Recall')\n",
    "ax.set_ylabel('Precision')\n",
    "ax.set_xlim(-0.05, 1.05)\n",
    "ax.set_ylim(0, 1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(8, 4)\n",
    "fig.set_dpi(dpi_high)\n",
    "for i in range(0, int(len(rfc_means_list))):\n",
    "    neigh_display = RocCurveDisplay.from_estimator(rfc_models[i], X_list[i][1], y_list[i][1], name=f'Random forest {name_list[i]}', \n",
    "                                                            color=color_list[i], linestyle=linestyle_list[i], ax=plt.gca())\n",
    "ax.set_title(\"Random Forest Combined AUROC\")\n",
    "ax.legend(loc='best', prop={'size': 8})\n",
    "ax.set_xlabel('Recall')\n",
    "ax.set_ylabel('Precision')\n",
    "ax.set_xlim(-0.05, 1.05)\n",
    "ax.set_ylim(0, 1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(8, 4)\n",
    "fig.set_dpi(dpi_high)\n",
    "for i in range(0, 4):\n",
    "    neigh_display = RocCurveDisplay.from_estimator(rfc_models[i], X_list[i][1], y_list[i][1], name=f'Random forest {name_list[i]}', \n",
    "                                                            color=color_list[i], linestyle=linestyle_list[i], ax=plt.gca())\n",
    "ax.set_title(\"Random Forest Combined AUROC\")\n",
    "ax.legend(loc='best', prop={'size': 8})\n",
    "ax.set_xlabel('Recall')\n",
    "ax.set_ylabel('Precision')\n",
    "ax.set_xlim(-0.05, 1.05)\n",
    "ax.set_ylim(0, 1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(8, 4)\n",
    "fig.set_dpi(dpi_high)\n",
    "for i in range(4, 8):\n",
    "    neigh_display = RocCurveDisplay.from_estimator(rfc_models[i], X_list[i][1], y_list[i][1], name=f'Random forest {name_list[i]}', \n",
    "                                                            color=color_list[i], linestyle=linestyle_list[i], ax=plt.gca())\n",
    "ax.set_title(\"Random Forest Combined AUROC\")\n",
    "ax.legend(loc='best', prop={'size': 8})\n",
    "ax.set_xlabel('Recall')\n",
    "ax.set_ylabel('Precision')\n",
    "ax.set_xlim(-0.05, 1.05)\n",
    "ax.set_ylim(0, 1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot confusion matrix for each classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_list = []\n",
    "heat_map_list = []\n",
    "\n",
    "temp_conf_mat = []\n",
    "temp_heat_map = []\n",
    "for i in range(0, int(len(rfc_means_list))):\n",
    "    conf_mat = confusion_matrix(y_list[i][1], rfc_test_prediction[i])\n",
    "    temp_conf_mat.append(conf_mat)\n",
    "    heat = pd.DataFrame(conf_mat, columns=np.unique(y_list[i][1]), index=np.unique(y_list[i][1]))\n",
    "    heat.index.name = 'Actual'\n",
    "    heat.columns.name = 'Predicted'\n",
    "    temp_heat_map.append(heat)\n",
    "\n",
    "confusion_matrix_list.append(temp_conf_mat)\n",
    "heat_map_list.append(temp_heat_map)\n",
    "\n",
    "fig, ax = plt.subplots(int(len(rfc_means_list)/4), 4, figsize=(20, 18))\n",
    "fig.subplots_adjust(left=None, bottom=None, right=2, top=None, wspace=None, hspace=0.3)\n",
    "\n",
    "sns.set(font_scale=1.4)\n",
    "lc = 'Grey'\n",
    "lw = 1\n",
    "col = -1\n",
    "row = 0\n",
    "for i in range(int(len(rfc_means_list))):\n",
    "    if i % 4 == 0:\n",
    "        col += 1\n",
    "        row = 0\n",
    "    else:\n",
    "        row += 1\n",
    "    \n",
    "    sns.heatmap(heat_map_list[-1][i], cmap='Greys', annot=True, annot_kws={'size': 16}, fmt='g', ax=ax[col, row], xticklabels=label, yticklabels=label, linecolor=lc, linewidths=lw)\n",
    "    ax[col, row].set_title(('Random Forest '+name_list[i]), fontweight='bold')\n",
    "sns.set(font_scale=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rc_file_defaults()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save output for model persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Model 1': [], 'Model 2': [], 'Model 3': [], 'Model 4': [], 'Model 5': [], 'Model 6': [], 'Model 7': [], 'Model 8': []}\n",
    "for i, model in enumerate(data):\n",
    "    data[model].append(rfc_means_list[i])\n",
    "    data[model].append(rfc_params_list[i])\n",
    "    data[model].append(rfc_best_result_list[i])\n",
    "    data[model].append(rfc_max_depth[i])\n",
    "    data[model].append(rfc_n_estimator[i])\n",
    "    data[model].append(rfc_max_features[i])\n",
    "    dump(rfc_models[i], f'models/output-rfc{i}.joblib')\n",
    "    data[model].append(rfc_accuracy[i])\n",
    "    data[model].append(rfc_precision[i])\n",
    "    data[model].append(rfc_recall[i])\n",
    "    data[model].append(rfc_f1[i])\n",
    "    data[model].append(rfc_classification_report[i])\n",
    "    data[model].append(rfc_test_prediction[i])\n",
    "    data[model].append(rfc_pr[i])\n",
    "    data[model].append(heat_map_list[0][i])\n",
    "    \n",
    "output_df = pd.DataFrame(data)\n",
    "index_list = ['rfc_means_list','rfc_params_list','rfc_best_result_list','rfc_max_depth','rfc_n_estimator','rfc_max_features','rfc_accuracy','rfc_precision','rfc_recall','rfc_f1','rfc_classification_report',\n",
    "                'rfc_test_prediction','rfc_pr','heat_map_rfc']\n",
    "output_df.insert(0, 'Name', index_list)\n",
    "output_df.set_index(output_df['Name'], inplace=True)\n",
    "output_df.drop('Name', axis=1, inplace=True)\n",
    "dump(output_df, 'models/output-rfc.joblib')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aef203514c858290544fd6a14248b5f64855080360fc299c24eb5474b48fd873"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
